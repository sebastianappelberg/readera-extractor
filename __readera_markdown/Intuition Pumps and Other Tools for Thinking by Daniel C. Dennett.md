# Intuition Pumps and Other Tools for Thinking by Daniel C. Dennett

Finished at: 2024-04-08
Last read at: 2024-07-01

## Comments

Page: 17

*Examples. Some philosophers think that using examples in their work is, if not quite cheating, at least uncalled for—rather the way novelists shun illustrations in their novels. The novelists take pride in doing it all with words, and the philosophers take pride in doing it all with carefully crafted abstract generalizations presented in rigorous order, as close to mathematical proofs as they can muster. Good for them, but they can’t expect me to recommend their work to any but a few remarkable students. It’s just more difficult than it has to be.*

**I would like to create a novel with lots of graphics but not quite a Manga or comic book. I wonder what a good format would be. The text and the images needs to flow into each other. 

---
Page: 26

*A few of the tools I present are actual software, friendly devices that can do for your naked imagination what telescopes and microscopes can do for your naked eye.*

**I wonder to what extent a tool like GPT could be used as a telescope for the mind. 

**Labels, examples, analogies and staging. There are probably other forms of thinking tools. 

**Being able to break down and reverse engineer intuition pumps will be a great skill to keep myself honest as well as be able to craft my own thinking tools. 

---
Page: 32

*Sometimes you don’t just want to risk making mistakes; you actually want to make them—if only to give you something clear and detailed to fix. Making mistakes is the key to making progress. Of course there are times when it is really important not to make any mistakes—ask any surgeon or airline pilot. But it is less widely appreciated that there are also times when making mistakes is the only way to go. Many of the students who arrive at very competitive universities pride themselves in not making mistakes—after all, that’s how they’ve come so much farther than their classmates, or so they have been led to believe. I often find that I have to encourage them to cultivate the habit of making mistakes, the best learning opportunities of all. They get “writer’s block” and waste hours forlornly wandering back and forth on the starting line. “Blurt it out!” I urge them. Then they have something on the page to work with.*

**I very much need to get better at making mistakes. Being stuck is way worse.

**What counts as fruitful mistakes?

---
Page: 32

*We philosophers have a taste for working on the questions that need to be straightened out before they can be answered. It’s not for everyone. But try it, you might like it.*

**Philosophers work on ill-defined problems. It's their goal to generate the necessary insights to turn it into a well-defined problem, after which philosophy ends and application picks up. 

---
Page: 35

*So when you make a mistake, you should learn to take a deep breath, grit your teeth, and then examine your own recollections of the mistake as ruthlessly and as dispassionately as you can manage. It’s not easy. The natural human reaction to making a mistake is embarrassment and anger (we are never angrier than when we are angry at ourselves), and you have to work hard to overcome these emotional reactions. Try to acquire the weird practice of savoring your mistakes, delighting in uncovering the strange quirks that led you astray. Then, once you have sucked out all the goodness to be gained from having made them, you can cheerfully set them behind you, and go on to the next big opportunity. But that is not enough: you should actively seek out opportunities to make grand mistakes, just so you can then recover from them.*

**Mistakes help us illuminate exactly what parts of our thinking that didn't work as well as why they didn't work. Enjoy your mistakes and learn as much as possible from them. Considering that it's the greatest source of creativity in the universe you should become a master at making grand mistakes. 

---
Page: 36

*This general technique of making a more-or-less educated guess, working out its implications, and using the result to make a correction for the next phase has found many applications. A key element of this tactic is making a mistake that is clear and precise enough to have definite implications.*

**There are better and worse mistakes to make. A mistake that is clear and precise will make learning from them easier. Trivial mistakes rarely lead to anything interesting. What kinds of mistakes lead to the most interesting conclusions? 

**Evolution discards mistakes and preserves what has worked in the past. Humanity is better at learning from their mistakes because we can share them publicly to everyone. As soon as one of us makes the mistake the whole population learns from it instantly. Instead of the incremental progress made by evolution.

---
Page: 44

*The idea that consciousness (of red, of pain, of anything) is some sort of network property, something that involves coordinated activities in myriads of neurons, initially may not be very attractive, but these attempts at reductios may help people see why it should be taken seriously.*

**Sometimes the answer is what's left after having disproven everything through reductio ad absurdum.  

---
Page: 46

*How to compose a successful critical commentary:
You should attempt to re-express your target’s position so clearly, vividly, and fairly that your target says, “Thanks, I wish I’d thought of putting it that way.”
You should list any points of agreement (especially if they are not matters of general or widespread agreement).
You should mention anything you have learned from your target.
Only then are you permitted to say so much as a word of rebuttal or criticism.
One immediate effect of following these rules is that your targets will be a receptive audience for your criticism: you have already shown that you understand their positions as well as they do, and have demonstrated good judgment (you agree with them on some important matters and have even been persuaded by something they said).*

**You're not going to respond with anything interesting unless you listen carefully and genuinely. 

---
Page: 49

*Let’s stipulate at the outset that there is a great deal of deplorable, stupid, second-rate stuff out there, of all sorts. Now, in order not to waste your time and try our patience, make sure you concentrate on the best stuff you can find, the flagship examples extolled by the leaders of the field, the prize-winning entries, not the dregs.*

**If you can critique something at its best, you'll be practicing your mind at the highest level and your critique will at least have a chance of not being part of the 90 percent pile of shit. This law sounds very similar to steelmaning.

---
Page: 52

*One of the least impressive attempts to apply Occam’s Razor to a gnarly problem is the claim (and provoked counterclaims) that postulating a God as creator of the universe is simpler, more parsimonious, than the alternatives. How could postulating something supernatural and incomprehensible be parsimonious? It strikes me as the height of extravagance, but perhaps there are clever ways of rebutting that suggestion. I don’t want to argue about it; Occam’s Razor is, after all, just a rule of thumb, a frequently useful suggestion. The prospect of turning it into a Metaphysical Principle or Fundamental Requirement of Rationality that could bear the weight of proving or disproving the existence of God in one fell swoop is simply ludicrous. It would be like trying to disprove a theorem of quantum mechanics by showing that it contradicted the axiom “Don’t put all your eggs in one basket.”*

**Take Occam's Razor for what it is, a heuristic that's useful for keeping theories tight and not bloated with anything unnecessary. It's a law of the universe. 

---
Page: 55

*The molecular biologist Sidney Brenner recently invented a delicious play on Occam’s Razor, introducing the new term Occam’s Broom, to describe the process in which inconvenient facts are whisked under the rug by intellectually dishonest champions of one theory or another. This is our first boom crutch, an anti-thinking tool, and you should keep your eyes peeled for it. The practice is particularly insidious when used by propagandists who direct their efforts at the lay public, because like Sherlock Holmes’s famous clue about the dog that didn’t bark in the night, the absence of a fact that has been swept off the scene by Occam’s Broom is unnoticeable except by experts. For instance, creationists invariably leave out the wealth of embarrassing evidence that their “theories” can’t handle, and to a nonbiologist their carefully crafted accounts can be quite convincing simply because the lay reader can’t see what isn’tthere.*

**Hiding known failure cases is pernicious indeed. How does one effectively spot this when you're not an expert? Try checking with the experts to see what they say.

**As important as it is to be on the lookout for hidden inconveniences, it's also important to scrutinize yourself and your own thinking to see if you've swept something under the rug consciously or unconsciously. It's important for practice using your thinking tools if you want to become proficient using them.

---
Page: 59

*Several times I have set up such exercises at Tufts, thanks to generous support from the administration. I handpick a small group of undergraduates (less than a dozen) and brief them on their role: they are not to accept anything they don’t understand. They will be expected to raise their hands, to interrupt, to alert the experts to anything they find confusing or vague. (They do get required reading to pore over beforehand so that they are not utter novices on the topic; they are interested amateurs.) They love the role, and so they should; they are being given made-to-order tutorials from some big guns. The experts, meanwhile, often find that being set the task (well in advance) to explain their position under these conditions helps them find better ways of making their points than they had ever found before. Sometimes these experts have been “protected” for years by layers of fellow experts, postdocs, and advanced graduate students, and they really need the challenge.*

**Preparing to explain something for people that you know are laypeople will push you to do at least two things. One, you will have to workout what assumptions are not obvious. Two, you will have to distill the essence of what you're explaining so as to make it easily digestible.

**Additionally you can be grateful for the benefit of solving the problem of experts talking past each other and having artifactual misunderstandings dissolved.

**How could one put together a lay audience cheaply? Rubber ducking may be enough. 

---
Page: 61

*Creativity, that ardently sought but only rarely found virtue, often is a heretofore unimagined violation of the rules of the system from which it springs. It might be the system of classical harmony in music, the rules for meter and rhyme in sonnets (or limericks, even), or the “canons” of taste or good form in some genre of art. Or it might be the assumptions and principles of some theory or research program. Being creative is not just a matter of casting about for something novel—anybody can do that, since novelty can be found in any random juxtaposition of stuff—but of making the novelty jump out of some system, a system that has become somewhat established, for good reasons. When an artistic tradition reaches the point where literally “anything goes,” those who want to be creative have a problem: there are no fixed rules to rebel against, no complacent expectations to shatter, nothing to subvert, no background against which to create something that is both surprising and yet meaningful. It helps to know the tradition if you want to subvert it. That’s why so few dabblers or novices succeed in coming up with anything truly creative.*

**I hadn't really thought about orderliness and conformity being the foundation from which you can make creative leaps. If everything is novel, nothing is creative. 

---
Page: 61

*Sit down at a piano and try to come up with a good new melody and you soon discover how hard it is. All the keys are available, in any combination you choose, but until you can find something to lean on, some style or genre or pattern to lay down and exploit a bit, or allude to, before you twist it, you will come up with nothing but noise. And not just any violation of the rules will do the trick. I know there are at least two flourishing—well, surviving—jazz harpists, but setting out to make your name playing Beethoven on tuned bongo drums is probably not a good plan. Here is where art shares a feature with science: there are always scads of unexamined presuppositions of any theoretical set-to, but trying to negate them one at a time until you find a vulnerable one is not a good recipe for success in science or philosophy. (It would be like taking a Gershwin melody and altering it, one note at a time, looking for a worthy descendant. Good luck! Almost always, mutations are deleterious.) It’s harder than that, but sometimes you get lucky.*

**Novelty is just one ingredient of creativity. Whatever you come up with has to be interesting as well. How does one define interesting?

---
Page: 62

*When you are confronting a scientific or philosophical problem, the system you need to jump out of is typically so entrenched that it is as invisible as the air you breathe.*

**How far can we break down our assumption tree? How do we know what's part of it? It's like the opposite of unknown unknowns. It's so known that it gets unknown. 

---
Page: 66

*Who says computers acting on inputs fed to them can’t actively generate probes? This familiar contrast between drearily “passive” computers and wonderfully “active” organisms has never been properly defended, and is one of the most ubiquitous imagination-blockers I know.*

**To see false dichotomies as imagination-blockers makes you realize that they're a mental warfare tool that aims to disable the opponent. 

---
Page: 66

*you can hunt for ratherings in a document more easily than you can hunt for false dichotomies, which never get announced as such; just type “rather” in your search box and see what comes up. Remember: not all “rather”s are ratherings; some are legitimate. And some ratherings don’t use the word “rather.”*

**I like how concrete this thinking tool is compared to some of the more abstract ones.

---
Page: 70

*When you’re reading or skimming argumentative essays, especially by philosophers, here is a quick trick that may save you much time and effort, especially in this age of simple searching by computer: look for “surely” in the document, and check each occurrence. Not always, not even most of the time, but often the word “surely” is as good as a blinking light locating a weak point in the argument, a warning label about a likely boom crutch. Why? Because it marks the very edge of what the author is actually sure about and hopes readers will also be sure about. (If the author were really sure all the readers would agree, it wouldn’t be worth mentioning.) Being at the edge, the author has had to make a judgment call about whether or not to attempt to demonstrate the point at issue, or provide evidence for it, and—because life is short—has decided in favor of bald assertion, with the presumably well-grounded anticipation of agreement. Just the sort of place to find an ill-examined “truism” that isn’t true!*

**I wonder if there are more assessment one can make about how the author views the reader based on other similar statements. I also wonder how one can use those further to deconstruct the author's argument. Could this be done already with a LLM?

---
Page: 73

*Here is a good habit to develop: Whenever you see a rhetorical question, try—silently, to yourself—to give it an unobvious answer. If you find a good one, surprise your interlocutor by answering the question. I remember a Peanuts cartoon from years ago that nicely illustrates the tactic. Charlie Brown had just asked, rhetorically, “Who’s to say what is right and wrong here?” and Lucy responded, in the next panel, “I will.”*

**Rhetorical questions are usually just sophistry. Avoid using them yourself, they're unbecoming of a good thinker.

---
Page: 75

*A deepity is a proposition that seems both important and true—and profound—but that achieves this effect by being ambiguous. On one reading it is manifestly false, but it would be earth-shaking if it were true; on the other reading it is true but trivial. The unwary listener picks up the glimmer of truth from the second reading, and the devastating importance from the first reading, and thinks, Wow! That’s a deepity.*

**It's the ultimate tool for people posing as intelligent and wise. Maybe it's an art in and of itself to put together cool sounding deepities. 

---
Page: 85

*The phenomena of intentionality are both utterly familiar—as salient in our daily lives as our food, furniture, and clothes—and systematically elusive from scientific perspectives. You and I seldom have difficulty distinguishing a birthday greeting from a death threat from a promise, but consider the engineering task of making a reliable death-threat-detector. What do all death threats have in common? Only their meaning, it seems. And meaning is not like radioactivity or acidity, a property readily discriminated by a well-tuned detector. The closest we have come yet to creating a general-purpose meaning-detector is IBM’s Watson, which is much better at sorting by meanings than any earlier artificial intelligence system, but notice that it is not at all simple, and would still (probably) misidentify some candidates for death threats that a child would readily get. Even small children recognize that when one laughing kid yells to another, “So help me, I’ll kill you if you do that again!” this is not really a death threat. The sheer size and sophistication of Watson are at least indirect measures of how elusive the familiar property of meaning is.*

**The aboutness and intentionality of things most likely doesn't reside in a particular structure in the brain. It's more like something organic and dynamic, something that requires our involvement and interaction with the world. 

**When you really think about it, it's really hard to tell what about something obvious makes it obvious. 

---
Page: 85

*If I try to inform you that salmon in the wild don’t wear hearing aids, you will tell me that this is not news to you, but when did you learn it? You weren’t born knowing it, it was not part of any curriculum at school, and it is extremely unlikely that you ever framed a sentence in your mind to this effect. So while it might seem obvious that Boris must have learned about the Frenchman by “simply uploading” the relevant Russian sentence in Pravda into his brain, and then “translating” it into, oh, Brainish, there is nothing obvious about the supposition that Boris’s brain performed a similar clerical job (from what into Brainish?) for the fact about salmon.*

**How do we immediately know the feasibility of a fact we hear for the first time? We're somehow able to parse the words into the aboutness of what the words are pointing to, then we're able to compare it to some expectations and then make a call whether it's far from the expected or not. We're able to relate new information to old information somehow. 

---
Page: 89

*What this intuition pump shows is that nobody can have just one belief. (You can’t believe a dog has four legs without believing that legs are limbs and four is greater than three, etc.)* It shows other things as well, but I won’t pause to enumerate them.*

**The object almost needs to become a living being inside your mental world model. 

---
Page: 88

*Still, meaning is not an utterly mysterious property. One way or another, structures in our brains somehow “store” our beliefs. When you learn that pudus are mammals, something has to change in your brain; something has to become relatively fixed in a way it wasn’t fixed before you learned this, and whatever it is must have enough aboutness, one way or another, to account for your newfound ability to identify pudus as closer kin to buffalos than to barracudas.*

**Learning is a process, and I think there are a lot of steps in that process that go by unnoticed, and that many of them are about gathering information and multiple perspectives on the thing you're learning. So that in a Frankenstein kind of way we can animate the concept into life inside of us, so that we can have a relationship with it. 

---
Page: 92

*Clearly her understanding of what it is to be a doctor, as well as what it is to be a father, will grow over the years, and hence her understanding of her own sentence, “Daddy is a doctor,” will grow. Can we specify—in any nonarbitrary way—how much she must know in order to understand this proposition “completely”? If understanding comes in degrees, as this example shows, then belief, which depends on understanding, must come in degrees as well, even for such mundane propositions as this. She “sorta” believes her father is a doctor—which is not to say she has reservations or doubts, but that she falls short of the understanding that is an important precondition for any useful concept of belief.*

**There's a gradient but I wonder if there's an elbow in the understanding curve that where the understanding quickly climbs over a certain threshold where the understanding is as accurate as it can be. It's easy to imagine for this very simple case but how would it work for extremely complex concepts that nobody fully understands?

---
Page: 94

*“The aim of philosophy, abstractly formulated, is to understand how things in the broadest possible sense of the term hang together in the broadest possible sense of the term.” That is the best definition of philosophy I have encountered. The task of figuring out how to put all the familiar things in our manifest image into registration with all the relatively unfamiliar things of the scientific image is not a job that scientists are especially well equipped to do. Please tell me, Dr. Physicist, just what a color is. Are there any colors according to your theory? Dr. Chemist, can you provide the chemical formula for a bargain? Surely (ding!) there are bargains. What are they made of? Hmm. Maybe there aren’t any bargains, not really! But then what’s the difference—the chemical difference?—between something that is a bargain and something that only seems to be a bargain?*

**It's funny how science doesn't seem to have an opinion on our qualia which is one of the things most near and dear to us.  

---
Page: 95

*An animal’s Umwelt consists in the first place of affordances (Gibson, 1979), things to eat or mate with, or shun, openings to walk through or look out of, holes to hide in, things to stand on, and so forth. An organism’s Umwelt is in one sense an inner environment, a “subjective” and even “narcissistic” ontology, composed of only the things that most matter to it, but its Umwelt is not necessarily inner or subjective in the sense of being conscious. Umwelt is really an engineering concept; consider the ontology of a computer-controlled elevator, the set of all the things it needs to keep track of in order to do its job.* One of von Uexküll’s studies was of the Umwelt of a tick. We may suppose that the Umwelt of a starfish or worm or daisy is more like the ontology of the elevator than like ourUmwelt, which is, in fact, our manifest image.
Our manifest image, unlike the daisy’s ontology or Umwelt, really is manifest, really is subjective in a strong sense. It’s the world we live in, the world according to us.† Like the daisy’s ontology, however, much of our manifest image has been shaped by natural selection over eons, and is part of our genetic heritage.*

**Humans have a lot of shared stories that we care about that are artificial. Technology, all kinds, including social and mental kinds, grows our umwelt without doing it through genes. 

**Is our manifest world the difference in our species specific ontology versus the ontology of the universe? I.e what ontology would make sense if we weren't here?

---
Page: 99

*Folk psychology is a talent we excel in without formal education. Folk physics then, in parallel fashion, is the talent we have for expecting liquids to flow, unsupported things to drop, hot substances to burn us, water to quench our thirst, and rolling stones to gather no moss. It’s another interesting question, how our brains manage to generate these almost always correct expectations so effortlessly, even if we’ve never taken a physics course.*

**There are so many extremely complicated things we do effortlessly. Physics, psychology, communication. We have to understand those more theoretically if we want to build intelligent agents. 

---
Page: 100

*Artists and philosophers agree on one thing: one of their self-appointed tasks is to “make the familiar strange.”* Some of the great strokes of creative genius get us to break through the crust of excessive familiarity, jootsing into the new perspective where we can look at ordinary, obvious things with fresh eyes. Scientists couldn’t agree more. Newton’s mythic moment was asking himself the weird question about why the apple fell down from the tree. (“Well, why wouldn’t it?” asks the everyday non-genius. “It’s heavy!”—as if this were a satisfactory explanation.)*

**Interesting things can be found in the things we so take for granted that we're blind to it. The fact that we're so close to the thing already, is why you can be sure that you're giving a new perspective on something people will care about.

**Comedians do this very well too. They give words to feelings we've all felt but haven't articulated well yet. 

---
Page: 102

*From an early age we effortlessly and involuntarily see others as agents, and not just happy or angry or baffled or afraid, but as in on the secret or wondering which way to turn or even unwilling to accept the deal offered. It isn’t brain surgery, or rocket science; it’s easy. The power and ease of use of folk psychology is due, I have argued, to the simplifying assumptions that enable it. It is like an idealized model in science—maximally abstract and stripped down to the essentials. I call this the intentional stance.*

**Doesn't it get a whole lot more intricate as we gain more experience and wisdom?

---
Page: 104

*The intentional stance is the strategy of interpreting the behavior of an entity (person, animal, artifact, or whatever) by treating it as if it were a rational agent who governed its “choice” of “action” by a “consideration” of its “beliefs” and “desires.”* The scare quotes around all these terms draw attention to the fact that some of their standard connotations may be set aside in the interests of exploiting their central features: their role in practical reasoning, and hence in the prediction of the behavior of practical reasoners.*

**What is it that makes us adopt the intentional stance as opposed to treating something as inanimate? When interacting with technology we usually do it because the designer of the technology designed it to be most efficiently used by assuming it to be a rational agent. 

---
Page: 105

*I propose we simply postpone the worrisome question of what really has a mind, about what the proper domain of the intentional stance is. Whatever the right answer to that question is—if it has a right answer—this will not jeopardize the plain fact that the intentional stance works remarkably well as a prediction method in these other areas, almost as well as it works in our daily lives as folk psychologists dealing with other people. This move of mine annoys and frustrates some philosophers, who want to blow the whistle and insist on properly settling the issue of what a mind, a belief, a desire is before taking another step. Define your terms, sir! No, I won’t. That would be premature. I want to explore first the power and the extent of application of this good trick, the intentional stance. Once we see what it is good for, and why, we can come back and ask ourselves if we still feel the need for formal, watertight definitions. My move is an instance of nibbling on a tough problem instead of trying to eat (and digest) the whole thing from the outset. Many of the thinking tools I will be demonstrating are good at nibbling, at roughly locating a few “fixed” points that will help us see the general shape of the problem. In Elbow Room (1984a), I compared my method to the sculptor’s method of roughing out the form in a block of marble, approaching the final surfaces cautiously, modestly, working by successive approximation. Many philosophers apparently cannot work that way and have to secure (or so they think) the utterly fixed boundaries of their problems and possible solutions before they can venture any hypotheses.*

**This is a great general problem solving strategy. Incrementally, iteratively chipping down at it. The other point which I think is good is that we don't have to know everything or be very rigorous to just play around with concepts, to experiment with them and see how they work. 

---
Page: 110

*This simple theory of intentional systems is a theory about how and why we are able to make sense of the behaviors of so many complicated things by considering them as agents. It is not directly a theory of the internal mechanisms that somehow achieve the rational guidance thereby predicted. The intentional stance gives you the “specs,” the job description, of an intentional system—what it should discriminate, remember, and do, for instance—and leaves the implementation of those specs to the engineers (or evolution and development, in the case of an intentional system that is an organism). Give me an agent that knows the difference between dollar bills and ten-dollar bills, can make change, detect counterfeits, and is willing and able to deliver the product the customer wants twenty-four hours a day. This intentional-stance characterization is either the specs for a vending machine or a rudimentary job description of a convenience store clerk, entirely noncommittal about what kind of innards or further talents the entity might have.*

**It's interesting that the jobs that the systems do are so much simpler than the machinery necessary for the systems to work. Why is the complexity of the function not exactly the complexity of its implementation? Maybe the question should instead be, why do I think that a job that requires so much complexity to be executed is simple? 

---
Page: 106

*So let’s see where the power of the intentional stance comes from, by comparing it with other tactics of anticipation. Let’s begin by identifying three main stances (which could be subdivided further for some purposes, but not ours here): the physical stance, the design stance, and the intentional stance.*

**How did these stances evolve? The design stance seems to be heavily influenced by humanity's capacity for technology. Are there more emergent stances coming? What stance should we adopt when thinking about larger scale systems like an economy, or an ecosystem? Is the intentionality stance enough then or is it misleading?

**Could collective phenomena like the economy be said to adopt a stance towards its own participants? 

---
Page: 110

*Like our capacity to understand entirely novel sentences of our natural languages, sentences we have never before heard in our lives, our ability to make sense of the vast array of human interactions bespeaks a generative capacity that is to some degree innate in normal people.*

**What supports generative knowledge? You face a novel setting, yet you're able to predict. World model, agent model, abstraction, what else?

---
Page: 114

*The brain’s multitudinous competences are so intertwined and interacting that there simply is no central place in the brain “where it all comes together” for consciousness.* For that matter, many of the competences, dispositions, preferences, and quirks that make you you depend on paths through your body outside your brain; the always popular philosophical thought experiment of the brain transplant (which would you rather be: the brain “donor” or the brain “recipient”?) is enabled by a very distorting idealization. As I once put it, “One cannot tear me from my body, leaving a nice clean edge”*

**It's a decentralized network, when does the emergent functions cease to work? I suppose, just as there are critical thresholds for phase transitions going up in complexity, there thresholds as you go down as well. Degrading gracefully so to speak. 

**At what scale would it be feasible to switch out every component of you and still have you be you. We do it at a cellular level right now, every 7 year but is that the limit? 

---
Page: 116

*At the cell level, the individual neurons are more exploratory in their behavior, poking around in search of better connections, changing their patterns of firing as a function of their recent experience. They are like prisoners or slaves rather than mere machines (like the protein nanobots); you might think of them as nerve cells in jail cells, myopically engaged in mass projects of which they have no inkling, but ever eager to improve their lot by changing their policies. At higher levels, the myopia begins to dissipate, as groups of cells—tracts, columns, ganglia, “nuclei”—take on specialized roles that are sensitive to ever-wider conditions, including conditions in the external world. The sense of agency here is even stronger, because the “jobs done” require considerable discernment and even decision-making.*

**What does the gradient of decision-making capacity look like? At what point does errors in the mechanics become possible?   Could an atom fail to do its job? What about a molecule or a protein or a cell or an organ?

**It's quite clear that this is highly related to Michael Levins idea of a cognitive light cone. It's frameworks like that, that will let us get into the weeds and start chipping away at the practical questions these ideas generate. 

---
Page: 117

*This idea, that we can divide and conquer the daunting problem of imagining how a person could be composed of (nothing but) mindless molecules, can be looked at bottom-up, as we have just done, or top-down, starting with the whole person and asking what smallish collection of very smart homunculi could conspire to do all the jobs that have to be done to keep a person going.*

**Bottom up seems more correct but also harder to understand.

**Top-down causality makes me think it's useful looking at it from both angles. It's also the only way we can do engineering right now. We'd need a science of engineering through bottom-up emergence, and with agential material. We'd have to be able to build complex systems, out of simpler systems. 

---
Page: 120

*The AI programmer begins with an intentionally characterized problem, and thus frankly views the computer anthropomorphically: if he solves the problem he will say he has designed a computer that can [e.g.,] understand questions in English. His first and highest level of design breaks the computer down into subsystems, each of which is given intentionally characterized tasks; he composes a flow chart of evaluators, rememberers, discriminators, overseers and the like. These are homunculi with a vengeance. … Each homunculus in turn is analyzed into smaller homunculi, but, more important, into less clever homunculi. When the level is reached where the homunculi are no more than adders and subtractors, by the time they need only the intelligence to pick the larger of two numbers when directed to, they have been reduced to functionaries who can be replaced by a machine. [p. 80]
The particular virtue of this strategy is that it pulled the rug out from under the infinite regress objection. According to homuncular functionalism the ominous infinite regress can be sidestepped, replaced by a finite regress that terminates, as just noted, in operators whose task is so dull they can be replaced by machines. The key insight was breaking up all the work we imagined being done by a central operator and distributing it around to lesser, stupider agents whose work was distributed in turn, and so forth.*

**This to me seems like the key to the halting problem, and thus the key to life. It's quite lucrative since it'd explain how we can go from something agential down to something mechanical. It's not fully satisfactory though since it doesn't explain how to go the other way around. It does but in a very limited way since it requires an already complex system. But how was it figured out to begin with? Maybe bruteforce search is fine here?

**The other major component to life is errors and error correction. And redundancy, so there is room to explore and adapt. 

---
Page: 122

*Notice that computers have always been designed to keep needs and job performance almost entirely independent. Down in the hardware, the electric power is doled out evenhandedly and abundantly; no circuit risks starving. At the software level, a benevolent scheduler system doles out machine cycles to whatever process has the highest priority, and although there may be a bidding mechanism of one sort or another that determines which processes get priority, this is an orderly queue, not a struggle for life. As Marx would have it, “From each according to his abilities, to each according to his needs.” The computer scientist Eric Baum has aptly dubbed this hierarchy “politburo” control. Probably a dim appreciation of this fact underlies the common folk intuition that a computer could never care about anything. Not because it is made out of the wrong materials—why should silicon be any less suitable a substrate for caring than carbon?—but because its internal economy has no built-in risks or opportunities, so it doesn’t have to care.*

**How would one program in a hardware environment where you have to compete for resources? What would a program like that have to do? Kill other programs, get closer to the resources? Lock the resources? What kind of hardware could withstand such an onslaught? The hardware would have to be like our physical world, it'd have to be very robust and adaptable, like mountains and water. It'd have to have limitless resources to go around but be very limited in local pockets. The local pockets is where the creatures would be  fighting for sunlight and minerals. 

---
Page: 123

*I now think, then, that the opponent-process dynamics of emotions, and the roles they play in controlling our minds, are underpinned by an economy of neurochemistry that harnesses the competitive talents of individual neurons. (Note that the claim is that neurons are still good team-players within the larger economy, unlike the more radically selfish agents, cancer cells. I recall Nobel laureate biologist François Jacob’s dictum that the dream of every cell is to become two cells; neurons vie to stay active and to be influential, but do not dream of multiplying.) In this view, intelligent control of an animal’s behavior is still a computational process—in the same way that a transaction in the stock market is a computational process—but the neurons are selfish neurons, as neuroscientist Sebastian Seung (2007) has said, striving to maximize their intake of the different currencies of reward we have found in the brain. And what do neurons buy with their dopamine, serotonin, or oxytocin? They are purchasing greater influence in the networks in which they participate, and hence greater security. (The fact that mules are sterile doesn’t stop them from fending for themselves, and neurons can similarly be moved by self-protective instincts they inherited ultimately from their reproducing ancestors.)*

**What does it mean for a neuron to be more fit than another one? What is the initial state of the network? How fast does it change? Are the changes continuous or discrete? Is it different depending on the level? What are the kinds of controls exhibited by and on neurons? Who do they push around and who pushes them around? Are there groups of neurons collaborating to gain a competitive edge? 

---
Page: 125

*This is the key to breaking the back of the mind-bogglingly complex question of how a mind could ever be composed of material mechanisms. At the dawn of the computer age, Alan Turing, who deserves credit as the inventor of the computer if anybody does, saw this prospect. He could start with mindless bits of mechanism, without a shred of mentality in them, and organize them into more competent mechanisms, which in turn could be organized into still more competent mechanisms, and so forth without apparent limit. What we might call the sorta operator is, in cognitive science, the parallel of Darwin’s gradualism in evolutionary processes (more on this in part VI). Before there were bacteria, there were sorta bacteria, and before there were mammals, there were sorta mammals, and before there were dogs, there were sorta dogs, and so on.*

**Can we get more rigorous than sort of? When can we expect phase transitions? Are they inherently unpredictable? 

---
Page: 126

*We use the intentional stance to keep track of the beliefs and desires (or “beliefs” and “desires” or sorta beliefs and sorta desires) of the (sorta-) rational agents at every level from the simplest bacterium through all the discriminating, signaling, comparing, remembering circuits that comprise the brains of animals from starfish to astronomers. There is no principled line above which true comprehension is to be found—even in our own case. The small child sorta understands her own sentence “Daddy is a doctor,” and I sorta understand “E = mc2.” Some philosophers resist this anti-essentialism (see chapter 43): either you believe that snow is white or you don’t; either you are conscious or you aren’t; nothing counts as an approximation of any mental phenomenon; it’s all or nothing. And to such thinkers, the powers of minds are insoluble mysteries because minds are “perfect,” and perfectly unlike anything to be found in mere material mechanisms.*

**In three pages he has pretty much converted me to a materialist. 

**I love the Aristotelian thinking present here. The world just consists of the particular. Everything is always sort of something. There are no clean boundaries. And at the same time, every level composed of the one below it is sort of stable. The My dad is a doctor argument, brought it home for me. A child sort of understands that her dad is a doctor, the way that I sort of understand complex mathematics. 

---
Page: 129

*Its value lies in the fact that any time we can make a computer do something that has seemed miraculous, we have a proof that it can be done without wonder tissue. Maybe the brain does it another way, maybe even with wonder tissue (maybe Randi is a real psychic, just like Geller!), but we have no good reason to believe it. Computers thus play an important role as demystifiers, and that is a good reason to insist on developing computer models of anything we are trying to understand, whether it be hurricanes or housing bubbles or HIV or human consciousness.*

**If we can program it, we understand it. Is that really the case though? A LLM could probably program a physics engine without knowing physics at all. And even if it did have algorithmic knowledge of it, it couldn't claim that it has felt its effects (unless it had appropriate sensors).

---
Page: 129

*The term wonder tissue is a thinking tool along the lines of a policeman’s billy club: you use it to chastise, to persuade others not to engage in illicit theorizing. And, like a billy club, it can be abused. It is a special attachment for the thinking tool Occam’s Razor and thus enforces a certain scientific conservatism, which can be myopic.*

**I like how every tool has a warning label on it. It promotes balanced use of it. 

---
Page: 136

*The alternative, putting a full-fledged Comprehender in the control room, confronted by all the inputs and outputs, is a guaranteed dead end. Why? Because if this power of comprehension is inexplicable, you have installed wonder tissue, a miracle, at the base of your theory, and if it is explicable—in terms of processes and activities and powers that do not themselves have the power of comprehension—you have wasted your turn and are right back at the beginning with those of us who are trying to explain how comprehension grows out of competence.*

**I don't know why this isn't more intuitive than it is. It's the basis of all good explanations, yet we struggle not to invoke wonder tissue. 

---
Page: 136

*Before there can be comprehension, there has to be competence without comprehension. This is nature’s way. Bacteria have all sorts of remarkable competences that they need not understand at all; their competences serve them well, but they themselves are clueless. Trees have competences whose exercise provides benefits to them, but they don’t need to know why. The process of natural selection itself is famously competent, a generator of designs of outstanding ingenuity and efficacy, without a shred of comprehension.*

**What is the set of base level competencies that we are born with? Our firmware. Our axioms of cognition from which we can develop the most advanced human thoughts. 

---
Page: 140

*We start by considering what is probably the simplest imaginable computer, a register machine, to see just what its powers are and why. We will then go on to see how a Turing machine, and a Von Neumann machine (such as your laptop) are just like register machines, only more efficient. (Anything your laptop can do, a register machine can do, but don’t hold your breath; it might take centuries.)*

**Interestingly though there are some phenomena where the rhythm of it is essential to what it is. The easiest example would be a video or animation. If the speed or the resolution of the video changes you get something different. If you massively bost the performance of it, it can do new things. 

---
Page: 141

*We need to know what computers can do and how they do it before we can responsibly address the question of whether or not our brains harbor and exploit incomprehensible or miraculous phenomena beyond the reach of all possible computers. The only satisfactory way of demonstrating that your brain isn’t—couldn’t be—a computer would be to show either (1) that some of its “moving parts” engage in sorts of information-handling activities that no computers can engage in, or (2) that the simple activities its parts do engage in cannot be composed, aggregated, orchestrated, computer-fashion, into the mental feats we know and love.*

**We're creeping closer and closer towards figuring out how to perform certain functions that we thought were unique to the brain. Having that said, are we close or are we still at the bottom of the mountain? 

---
Page: 143

*Here is a striking way of looking at it: the register machine can add two numbers together perfectly without knowing which numbers it is adding (or what numbers are or what addition is)!*

**The process, the algorithm itself contained the knowledge of addition without any part of the system explicitly knowing what it is. In the case of this program, we designed the algorithm and we had the knowledge of what it means. How does this transfer to our brains? Every algorithm we're running in our brain has had to evolve. Does plain old evolution become less of a factor at some point? I could see a person explicitly designing changes in the way they think. 

---
Page: 147

*We can analyze the loops, to see what each does. First we zero out the answer register, register 3, and then we zero out a spare register (register 4) to use as a temporary holding tank or buffer.*

**This seems to be assuming that the program is not started with a clean slate. This makes sense if you have multiple programs sharing the same registers. 

---
Page: 154

*As you can now see, Deb, Decrement-or-Branch, is the key to the power of the register machine. It is the only instruction that allows the computer to “notice” (sorta notice) anything in the world and use what it notices to guide its next step. And in fact, this conditionalbranching is the key to the power of all stored-program computers*

**What are the lowest level instructions at work in our brain and body? It seems to me that computation is necessary in every part of our body. Of the computation that's actually related to our thoughts, what portion of it is in the brain?

---
Page: 155

*SECRET 2: What a number in a register stands for depends on the program that we have composed.*

**I suppose that nature is grateful to have such flexible machinery to work with. We can randomly throw in the meaning of an instruction. Just cram it in there with the rest. And it'll be fine since the amount of space for writing code is limited only by the size of our DNA, and in the case of our brain the amount of neurons and their connections. 

---
Page: 155

*SECRET 3: Since a number in a register can stand for anything, this means that the register machine can, in principle, be designed to “notice” anything, to “discriminate” any pattern or feature that can be associated with a number—or a number of numbers.*

**Is there anything that can't be mapped to a number? Every possible combination of words can be represented by a number. Can processes be represented by a number? Sure, if the number points to another complex operation, like the mapping to ADD, SUB, etc. Those operations could in theory grow to be massively complex. One limiting factor is that complexity becomes harder and harder to manage the more you have of it. You need to somehow let go of control and grow additional complexity organically. At what point do you need to make that strategy shift?

---
Page: 158

*A Universal Turing machine is a device with a program A (hardwired, if you like) that permits it to “read” its program B off its paper tape and then execute that program using whatever else is on the tape as data or input to program B. Hao Wang’s register machine can execute any program that can be reduced to arithmetic and conditional branching, and so can Turing’s Turing machine. Both machines have the wonderful power to take the number of any other program and execute it. Instead of building thousands of different computing machines, each hardwired to execute a particular complicated task, we build a single, general-purpose Universal machine (with program A installed), and then we can get it to do our bidding by feeding it programs—software—that create virtual machines.*

**This hardwired program, the universal machine, what does it look like in life? Does it look the same for every organism? I'd again like to differentiate between our genetic code and our cognitive abilities. Perhaps the difference is the same as computer code and neural networks. One deals with morphology and one deals with cognition. 

---
Page: 158

*SECRET 6: All the improvements in computers since Turing invented his imaginary paper-tape machine are simply ways of making them faster.*

**How is it that we have so much compute power and still aren't able to beat humans in every possible cognitive task? It's true that as soon as we figure out the principles of some task and we understand it well enough to code it, computers are immediately more efficient. It's not the compute that's missing, it's the lack of good software. 

---
Page: 164

*A virtual machine is what you get when you impose a particular pattern of instructions (more literally, dispositions) on a real machine that has lots of plasticity—interacting parts that can be in many different states. Since a virtual machine does informational work, it can do the same job as a computer whose “moving parts” are state-changes in hardware by making all those state-changes in representations of those moving parts. You can do long division with a pencil on a piece of paper, or if you are really good at long division, you can do it “in your head” by just representing—imagining—the marks on an imaginary page or blackboard. The yield is just as good either way since it’s information: an answer.*

**Viewing programs as specialized machines is a new perspective for me. The computation is virtualized, and the answer can easily be bridged onto something actualized. The program in the end leads to some hardware actualization. A pixel is shifted, signals are sent through the network, data is stored, etc. 

---
Page: 169

*We don’t yet know how to describe such different levels in the activities of brains of people playing chess or speaking French.* No doubt there will be nothing like the precise mappings that have enabled computer programmers to design their inventions at the highest levels with full confidence that a running program will emerge from the compiler (a program that takes the high-level instructions and translates them into code that can run on the hardware). But we do now have an important proof of concept: we know at least one way to make sense of the high-level competences of a machine with trillions of moving parts—without invoking any wonder tissue.*

**Maybe we're missing yet another level to wield complexity sufficient to constitute life and intelligence? What is the highest possible level of programming? 

---
Page: 177

*Imagine you’ve written a chess program, and you feed its source code to two different compilers. Then play the two compiled versions against each other on the same computer. Even though the two versions “think all the same thoughts in the same order” (they have to—they have exactly the same source code), one may always beat the other simply because it thinks those thoughts faster, using fewer basic machine cycles, and hence can look farther ahead during the time available!*

**You mustn't forget that the actual capacity of a program will always depend on both the software and the hardware. A shift in hardware performance may open up new possibilities. 

---
Page: 177

*Source code has to be very carefully composed according to a strict syntax, with every element in the right place and all the punctuation in the right order, since it has to be fed to a compiler program, which takes the source code and translates it into the sequences of fundamental operations (in object code) that the actual machine (or virtual machine) can execute. A compiler can’t be asked to guess what a programmer means by a line of source code; the source code must tell the compiler exactly what operations to perform—but the compiler program may have lots of different ways of performing those tasks and will be able to figure out an efficient way under the circumstances.*

**It does feel like the compiler of life is less picky. Or maybe not,  maybe that's why mutations are almost always bad. It's basically programming by bruteforce through a highly parallel and incremental process. The incremental part is extremely important, starting from scratch and then falling to the bottom every time would've not led to anything. 

---
Page: 182

*Turing saw that in one sense this was inescapable: intelligent processes would always require choosing one course or another on the basis of the discrimination of some difference in the signal. But he could reduce this understanding to the barest minimum: conditional branching, the mindless process by which a device decides (sorta decides) to go left rather than right because it senses (sorta senses) 1 rather than 0, A rather than B, x rather than y. That, and arithmetic, were all you needed. You could then build up devices of any level of discernment by piling virtual machines on top of virtual machines on top of virtual machines—to put it anachronistically.*

**Turing kind of did for cognition what Darwin did for biology. He removed to need for magic. 

---
Page: 187

*We human beings encounter lots of declarative sentences, spoken and written, in the course of a day, and we thereby come to know all manner of facts (and believe a smattering of falsehoods). Some we store in libraries and archives, and some we store only in our brains. We seldom memorize the actual sentences, word for word, but when we salt away the gist of an encountered sentence, it must be—mustn’t it?—a matter of storing a sentence-like something-or-other, a formula in Brainish. If this isn’t so, what are the alternatives?*

**How does it feel to know something? Someone asks you something, and you feel something and then you respond. It depends on what they're asking for. If it's about a concrete object, usually some imagery happens. If it's about something abstract like what does it mean to be good, there's usually imagery as well but a little bit more abstract. You try to embody being exposed to the concept. 

**Storing knowledge as the sentences you read seems absurd, I don't think I can recall a single sentence from any book verbatim. I can recall some things in my own words but even that is hard when I haven't really learned the material. 

---
Page: 188

*That is, it might be impossible to characterize the role of this thing as a belief, weirdly specific or weirdly vague, that allredheadsareF … (where we cash out “F” with whatever content seems to do the most justice to Mike’s attitude). Mike certainly has an attitude about redheads, but it isn’t any particular propositional attitude, to use the philosophical jargon. In other words, it defies categorization in the format
Mike believes that: for all x, if x is a redhead then …,
no matter how deviously we pile on the exclusion clauses, qualifiers, probability operations, and other explicit adjusters of content. Philosophers (and other theorists) have often tried to “reduce” all cognitive states to information-bearing states—call them beliefs and desires—that can be expressed in such formulas, and while the tactic is a great way of providing a rough sketch of some person’s psychology (it’s the intentional stance, in effect), the idea of making it ultra-precise is hopeless. We can say, if we like, that various beliefs are implicit in the system. What this means is that the system is (currently) designed to operate “under the assumption” that the world’s redheads have such-and-such features. When computer programmers put a comment on the source code, telling everyone that this system relies on a defined set of assumptions, they know enough not to devote labor trying to render the propositions precise, because they appreciate that these are mnemonic labels for us observers, not anything the computer has to sorta read and sorta understand, and even for us observers the comments are not specifications of content that can be used the way a chemist uses formulae to describe molecules. Giving an intentional-stance interpretation of some sub-personal brain structure is like putting a comment on a few lines of code; when done well, it provides an illuminating label, not a translation into English or other natural language of some formula in Brainish that the brain is using in its information-processing. By missing this trick, some philosophers have created fantasy worlds of internal sentence-manipulating machinery, where it is imagined to make all the difference whether the content of a particular brain event is expressed using a disjunctive predicate (I see a boy-OR-girl) or with a predicate lacking logical structure (I see a child), for instance.*

**I love the comparison of our attempted explanations of the mind as comments in code. It points to the very important notion that the explanation is not the thing, in fact it can be very far from it. 

**Our beliefs and our knowledge cannot be reduced to first order logic. The way that our knowledge is implemented is almost like it's sub propositional, much like Vervaeke claims. 

**It feels like combinatorics is involved, we can relate a whole bunch of different concepts with one another and see everything from different aspects. Any representation we have can be flexibly used everywhere else and still maintain its integrity. A dog in a park versus a dog at home, is still a dog.

---
Page: 193

*(Look how many times I’ve used the sorta operator in this paragraph, so that I can use the intentionalstance when giving you the specs of the two-bitser. Try to rewrite the paragraph without using the intentional stance and you will appreciate how efficient it is, and how well-nigh indispensable the sorta operator can be for such purposes.)*

**If we didn't talk about things as agents we'd have to write out a manual for every little thing. We have to use declarative, high-level language to not drown in details. 

---
Page: 193

*If objects of kind K became more common in the two-bitser’s normal environment, we would expect the owners and designers of two-bitsers to develop more advanced and sensitive transducers that would reliably discriminate between genuine U.S. quarters and slugs of kind K. Of course, trickier counterfeits might then make their appearance, requiring further advances in the detecting transducers, and at some point such escalation of engineering would reach diminishing returns, for there is no such thing as a foolproof mechanism. In the meantime, the engineers and users are wise to make do with standard, rudimentary two-bitsers, since it is not cost-effective to protect oneself against negligible abuses.*

**The funny thing is that spying done by intelligence agencies fall under those kinds of negligible abuse cases. Since they only take action on a few of their Spyware traps we don't bother trying to suppress them. 

---
Page: 193

*The only thing that makes the device a quarter-detector rather than a slug-detector, or a quarter-or-slug-detector, is the shared intention of the device’s designers, builders, owners, and users. Only in the environment or context of those users and their intentions can we single out some of the occasions of state Q as “veridical” and others as “mistaken.” It is only relative to that context of intentions that we could justify calling the device a two-bitser in the first place.*

**An iPhone could be called a spydevice, but the intention of it is to be a smartphone. 

---
Page: 196

*To start with the simplest inroad into this topic, suppose the two-bitser (to refer to it by the name of its original baptism) is equipped with a counter, which after ten years of service stands at 1,435,792. Suppose it is not reset to zero during its flight to Panama, so that on its debut there the counter turns over to 1,435,793. Does this tip the support in favor of the claim that it has not yet switched to the task of correctly identifying quarter-balboas? (After all, it sorta misclassifies the event as yet another one of those q events—detections of U.S. quarters—it was designed to detect.) Would variations and complications on this theme drive your intuitions in different directions? (Turn all the knobs on the intuition pump to see what happens to your intuitions.)*

**It's easy to feel how historicity doesn't really matter in this case. It has a new purpose, the intention is now for it to be a q-balber. 

**How will the coins be used after they've been put in? Is that outside of its domain? 

**The two-bitser wouldn't necessarily suffer if its purpose changes. For machines whose purpose is part of its structural functional organization, like goal driven agents, then switching the purpose seems more difficult. 

---
Page: 200

*These two basic strategies are obviously copied from nature: they correspond roughly to the division between plants and animals. A third option from nature, a hardened spore or seed that can survive indefinitely inside its armor, is not available to you, since your life-support system has high energy demands, and spores are as inert and low energy as nature can make them. Since the animal strategy fits our purposes, we shall suppose that you decide to build a robot to house your capsule. You should try to design it so that above all else it “chooses” actions that will further your best interests. Bad moves and wrong turns would tend to incapacitate it for the role of protecting you until 2401—which is its sole raison d’être. This is clearly a profoundly difficult engineering problem, calling for the highest level of expertise in designing a “vision” system to guide its locomotion, and other “sensory” systems. And since you will be comatose throughout and thus cannot guide and plan its strategies, you will have to design it to generate its own plans in response to changing circumstances. It must “know” how to “seek out” and “recognize” and then exploit energy sources, how to move to safer territory, how to “anticipate” and then “avoid” dangers. With so much to be done, and done fast, you had best rely on economies whenever you can: give your robot no more discriminatory prowess than it will probably need to distinguish what needs distinguishing in the world.*

**If you could code a robot that'd carry on a piece of information forever, how would you do it? What capacities and behaviors would you give it? If you got to design life, hoe would you design it? 

---
Page: 201

*It would no doubt be wise to design your robot with enough sophistication in its control system to permit it to calculate the benefits and risks of cooperating with other robots, or of forming alliances for mutual benefit, but again, any such calculation must be a “quick and dirty” approximation, arbitrarily truncated by time pressure.*

**This is where a capacity for relevance realization becomes relevant. It's also where the designed intent starts to lose some of its control. 

---
Page: 202

*But it is also true that given the artificer’s goal of making a good chess-playing computer, many of the artificer’s decisions concerning what the computer’s states are (derivedly) about are forced on the artificer: given the fact that a chess player needs accurate information about the rules and the state of the game, there must be states that concern each bishop and each pawn, and states that involve an evaluation of the game if the computer’s queen captured the opponent’s knight on the current move, and so forth. And no amount of authorial fiat could make a state of the computer be (derivedly) about the number of pawns remaining on the board if that state wasn’t appropriately linked to locating each and every pawn on the board.*

**The environment and the context play an unignorable role in affecting designs. You cannot make something in a vacuum and hope it'll be fit for purpose. 

---
Page: 205

*While it can never be stressed enough that natural selection operates with no foresight and no purpose, we should also not lose sight of the fact that the process of natural selection has proved itself to be exquisitely sensitive to rationales, making myriads of discriminating “choices” and “recognizing” and “appreciating” many subtle relationships. To put it even more provocatively, when natural selection selects, it can “choose” a particular design for one reason rather than another, without ever consciously—or unconsciously!—“representing” either the choice or the reasons. Hearts were “chosen” for their excellence as blood-circulating pumps, not for the captivating rhythm of their beating, though that might have been the reason some other thing was “chosen” by natural selection.*

**The reason is built into the process, and the interaction of the artifacts and their environment. 

---
Page: 204

*This vision of things, while it provides a satisfying answer to the question of whence came our own intentionality, does seem to leave us with an embarrassment, for it derives our own intentionality from entities—genes—whose intentionality is a paradigm case of mere as if intentionality. How could the literal depend on the metaphorical?*

**The key is that emergence can come from simple components and their interactions. Much like the register machine, whose processes and components were extremely simple but put together the right way those components can compute anything. 

---
Page: 206

*First, if we are “just” artifacts, then what our innermost thoughts mean—and whether they mean anything at all—is something about which we, the very thinkers of those thoughts, have no special authority. The two-bitser turns into a q-balber without ever changing its inner nature; the state that used to mean one thing now means another. The same thing could in principle happen to us, if we are just artifacts, if our own intentionality is thus not original but derived. (Jones, for instance, is not authoritative about whether he is thinking about horses or schmorses.) Second, if we are such artifacts, not only have we no guaranteed privileged access to deeper facts that fix the meanings of our thoughts, but there areno such deeper facts. Sometimes functional interpretation is obvious (the heart is obviously a pump; the eye is obviously for seeing), but when it is not, when we go to read Mother Nature’s mind, there is no text to be interpreted. When “the fact of the matter” about proper function is controversial—when more than one interpretation is well supported—there simply is no fact of the matter.*

**We shouldn't be disheartened by this, we should feel connected to a greater whole, something that is beyond our individual selves, we lose control but we gain connectedness. 

---
Page: 210

*It is possible to construct such a puzzle because there are norms for definitions that admit some flexibility. Both solutions include words that just barely fit their definitions, but the conspiracy of the surrounding fit (the holism, in the jargon of philosophers) pulls the words into two quite stable configurations. What odds would you take that there isn’t going to be a third solution that competes evenly with either of these two? In general, the cryptographer’smaxim holds: if you can find one solution to a puzzle, you’ve found the only solution to the puzzle. Only special circumstances permit as many as two solutions, but such cases show us that the existence of only one single solution to a question like this is not a metaphysical necessity, but just the immensely probable result of very powerful constraints.*

**The likelihood decreases exponentially, however the world is asymmetrically impacted by black swan events so we shouldn't dismiss the impact of the very unlikely but not impossible. 

---
Page: 210

*The reason we don’t have indeterminacy of radical translation is not because, as a matter of metaphysical fact, there are “real meanings” in there, in the head (what Quine called the “museum myth” of meaning, his chief target). The reason we don’t have indeterminacy in the actual world is that with so many independent constraints to satisfy, the cryptographer’s maxim assures us that it is a vanishingly small worry. When indeterminacy threatens in the real world, it is always just more “behavioral” or “dispositional” facts—more of the same—that save the day for a determinate reading, not some mysterious “causal power” or “intrinsic semanticity.” Intentional interpretation almost always arrives in the limit at a single interpretation, but in the imaginable catastrophic case in which dual interpretations survived all tests, there would be no deeper facts to settle which was “right.” Facts do settle interpretations, but it is always “shallow” facts that do the job.*

**Does the design constraints not constitute the interpretation?   It would still just be an additional fact. 

---
Page: 213

*Brains, in other words, are supposed to be semantic engines. What brains are made of is kazillions of molecular pieces that interact according to the strict laws of chemistry and physics, responding to shapes and forces; brains, in other words, are in fact only syntactic engines.*

**I think even the possibility of a LLM is evidence of this claim. We're able to extract semantic structure from syntactic structure.

---
Page: 213

*Imagine going to the engineers and asking them to build you a genuine-dollar-bill-discriminator, or, what amounts to the same thing, a counterfeit-detector: its specs are that it should put all the genuine dollars in one pile and all the counterfeits in another. Not possible, say the engineers; whatever we build can respond only to “syntactic” properties: physical details—the thickness and chemical composition of the paper, the shapes and colors of the ink patterns, the presence or absence to other hard-to-fake physical properties. What they can build, they say, is a pretty good but not foolproof counterfeit-detector based on such “syntactic” properties. It will be expensive, but indirectly and imperfectly it will test for counterfeit-hood well enough to earn its keep.
Any configuration of brain parts is subject to the same limitations. It will be caused by physicochemical forces to do whatever it does regardless of what the input means (or only sorta means). Don’t make the mistake of imagining that brains, being alive, or made of proteins instead of silicon and metal, can detect meanings directly, thanks to the wonder tissue in them. Physics will always trump meaning.*

**The brain seems to go beyond just using single variables to make predictions, it selects and combines variables in ways that massively improves its capacity for meaning making. It's almost like it has an insanely fast simulation engine that let's it play around with the thing under observation and have it interact with other concepts in the brain. And somehow it manages to play with it in the right environment and context for it. Perhaps it actually bruteforces, just that it has a really quick, perhaps parallel, way of eliminating unsuitable contexts. 

---
Page: 219

*Settling the verdict on imaginary cases that violate these conditions serves no purpose that I can see. In fact, such labored examples strike me as manufactured opportunities to impose an imaginary dichotomy so that you can rather with impunity. “No,” says the philosopher. “It’s not a false dichotomy! For the sake of argument we’re suspending the laws of physics. Didn’t Galileo do the same when he banished friction from his thought experiment?” Yes, but a general rule of thumb emerges from the comparison: the utility of a thought experiment is inversely proportional to the size of its departures from reality.*

**It's about twisting and turning, zooming in and out, in order to try to generate insights. With new insights we can potentially reframe the problem and make it tractable. 

---
Page: 229

*Al and Bo may live in different countries and have different native languages, but they inhabit the same world, and (ii) although there are kazillions of true propositions about that world (our world), the fact that both Al and Bo set out to create useful databases would guarantee a high degree of overlap between the two independently created systems. Although Al might know that on his twentieth birthday his left foot was closer to the North Pole than the South Pole, and Bo had not forgotten that his first French teacher was named Dupont, these would not be truths that either one would likely put in their respective databases. If you doubt that the mere fact that they were each intent on creating an internationally useful encyclopedia would ensure such a close correspondence between their respective databases, just add, as an inelegant detail, the convenient fact that during their years of hacking they compared notes as to topics to be covered.*

**How does this type of convergence relate to relevance realization? Since the people who made it are similar, and the goal they had when making it was the same, how much should we expect the solutions to overlap?

---
Page: 230

*In the story as told, we can agree that it is bizarre that the scientists never thought of checking to see if there was an ASCII translation of the bit streams running through the wire. How could they be so dense? Fair enough: you can fix this flaw in the thought experiment by sending the whole gadget (boxes A and B, and the connecting wire) to “Mars,” and let the alien scientists there try to figure out the regularity.*

**There seems to be a structured way of composing intuition pumps. What is the concept you want to highlight? What knobs do you need to turn to isolate it completely? 

---
Page: 231

*When I tried this thought experiment out on Danny Hillis, the creator of the Connection Machine, a pioneering massively parallel computer built by his company, Thinking Machines, in the early 1980s, he thought immediately of a cryptographic “solution” to the puzzle, and then granted that my solution could be profitably viewed as a special case of his solution: “Al and Bo were using the world as a ‘one-time pad!’ ”—an apt allusion to a standard technique of encryption. You can see the point by imagining a variation.*

**The first thing I thought about too was cryptography. 

---
Page: 231

*The point of the fable is simple. There is no substitute for the intentionalstance; either you adopt it, and explain the pattern by finding the semantic-level facts, or you will forever be baffled by the regularity—the causal regularity—that is manifestly there.*

**Even though syntax is what's there at the bottom, semantics is essential to explaining the world. Levels of description come to mind, would you explain why you're sad by the momentum of particles in your brain or would you rather just say that you're sad because you lost someone? 

---
Page: 244

*It is amusing to think about some of the volumes that must be somewhere in the Library of Babel. One of them is the best, most accurate five-hundred-page biography of you, from the moment of your birth until the moment of your death. Locating it, however, would be all but impossible, since the Library also contains kazillions of volumes that are magnificently accurate biographies of you up until your tenth, twentieth, thirtieth, fortieth birthday, and so on, and completely false about subsequent events of your life—in a kazillion different and diverting ways. But even finding one readable volume in this huge storehouse is unlikely in the extreme.*

**It's a fun way of thinking about an extremely large state space. It's not infinite though, I don't know what impact that has in practice.

---
Page: 246

*Moby-Dick is in the Library of Babel, but so are 100,000,000 mutant impostors that differ from the canonical Moby-Dick by a single typographical error. That’s not yet a Vast number, but the total rises swiftly when we add the variants that differ by two or ten or a thousand typos. Even a volume with a thousand typos—two per page on average—would be unmistakably recognizable as Moby-Dick, and there are Vastly many of those volumes. It wouldn’t matter which of these volumes you found, if only you could find one of them! Almost all of them would be equally wonderful reading, and all tell the same story, except for truly negligible—almost indiscriminable—differences. Not quite all of them, however. Sometimes a single typo, in a crucial position, can be fatal.*

**What separates a deleterious mutation from a safe one? And same for a beneficial mutation? What if there are versions of Moby Dick that are superior to the original? Is that a valid possibility? When does it stop counting as Moby Dick?

---
Page: 247

*This galaxy is in itself Vastly larger than the whole physical universe, so no matter what direction you go in, for centuries on end, even if you travel at the speed of light, all you see are virtually indistinguishable copies of Moby-Dick. You will never ever reach anything that looks like anything else. David Copperfield is unimaginably distant in this space, even though we know that there is a path—the shortest path, ignoring the kazillions of others—leading from one great book to the other by single typographical changes. (If you found yourself on this path, you would find it almost impossible to tell, by local inspection, which direction to go to move toward David Copperfield, even if you had texts of both target books in hand.)*

**What if you indexed the space based on the essence of the books? The Moby Dick essence would bring you to the Moby Dick galaxy and the David Copperfield essence would bring you to that galaxy. We have a way of nearly doing this with embeddings. What happens when we use embeddings to search through the genome?

---
Page: 249

*Moreover, mutations accumulate at the rate of about a hundred per genome per generation in mammals. “That is, your children will have one hundred differences from you and your spouse in their genes as a result of random copying errors by your enzymes or as a result of mutations in your ovaries or testicles caused by cosmic rays”*

**That sounds like a really small rate of mutations. Very interesting that it's so stable. Why is it so slow? Or is it actually really fast? Hoe does population size impact the total compute capacity?

---
Page: 250

*Most DNA sequences—the Vast majority—are gibberish, recipes for nothing living at all. All the genomes that we see, that actually exist today, are the products of billions of years of adjustment and revision, a mindless editorial process that is effective because most of the gibberish (all but a Vanishingly thin thread of meaningful, useful “text”) is automatically discarded, while the rest is relentlessly reused, copied kazillions of times. You have more than a trillion copies of your genome in your own body right now, one copy in each human cell, and every day, as new skin cells and bone cells and blood cells are made, new copies of your genomes are installed in them. The text that can be copied—because it resides in a going concern, a living cell—is copied. The rest dissolves. Publish or perish.*

**How do you kick off a process like this artificially? What happens if you just let it run? Does the creatures in the game of life have something like DNA?

---
Page: 253

*In one respect the analogy with words is misleading. Words are shorter than genes, and some writers have likened each gene to a sentence. But sentences aren’t a good analogy, for a different reason. Different books are not put together by permuting a fixed repertoire of sentences. Most sentences are unique. Genes, like words but unlike sentences, are used over and over again in different contexts. A better analogy for a gene than either a word or a sentence is a toolbox subroutine in a computer. …
The Mac has a toolbox of routines stored in RoM (Read Only Memory) or in System files permanently loaded at startup time. There are thousands of these toolbox routines, each one doing a particular operation, which is likely to be needed, over and over again, in slightly different ways, in different programs.*

**So what is the higher order program that decides to call which subroutines and in which order? Is it subroutines all the way down? Meaning what's orchestrating the subroutines is itself a subroutine. Is it meaningful to draw distinctions between those? They seem to be called controlling genes. Are we selected at a subroutines level? Maybe we're thinking too small when we do evolutionary programming, maybe the nodes need to more complex. What's the range of complexity of what a gene can accomplish? And I suppose a set of genes. The combinatorial nature of subroutines is what builds complexity. 

---
Page: 262

*The biosphere is utterly saturated with design, with purpose, with reasons. What I call the design stance predicts and explains features throughout the living world using the same assumptions that work so well when we are reverse engineering artifacts made by (somewhat) intelligent human designers. Evolution by natural selection is a set of processes that “find” and “track” reasons for things to be arranged one way rather than another. The chief difference between the reasons found by evolution and the reasons found by human designers is that the latter are typically (but not always) represented in the minds of the designers, whereas the reasons uncovered by natural selection are typically represented for the first time by the human investigators who succeed in reverse engineering nature’s productions. That is to say, human designers think about the reasons for the features of their artifacts, and hence have ideas that represent the reasons. They typically notice, appreciate, formulate, refine, and then convey, discuss, criticize the reasons for their designs. Evolution doesn’t do any of this; it just sifts mindlessly through the variation it generates, and the good stuff (which is good for reasons, reasons undreamed of or unrepresented by the process of natural selection) gets copied.*

**It's refreshing to so fiercely talk about design in nature. And of course it's true, let's not make rhetoric a reason not to talk clearly. The kinds of designs that we see by nature versus man should highlight the difference and similarities in the processes. Sometimes human designs get a kind of organic feel to them, but that's usually when several people have been involved over many years. The process has then turned a bit more into an evolutionary one. Think of the design of some cities. 

---
Page: 268

*Let us understand that a skyhook is a “mind-first” force or power or process, an exception to the principle that all design, and apparent design, is ultimately the result of mindless, motiveless mechanicity. A crane, in contrast, is a subprocess, or a special feature of a design process that can be demonstrated to permit the local speeding up of the basic, slow process of natural selection, and that can be demonstrated to be itself the predictable (or retrospectively explicable) product of the basic process. Some cranes are obvious and uncontroversial; others are still being argued about, very fruitfully.*

**Cranes are so much simpler to wrap your head around. Every complex system is made out of simpler systems and components. And you can put together one complex system with another one to yield an even more complex system.

---
Page: 268

*(“Technology transfer” does not always or even often yield good results, but when it does, it can be spectacular.) Neither lineage had to go to the plodding trouble of reinventing all the tricks and systems of the other, and since the combination of their talents happened to be a net gain (synergy is the buzzword for this), this eu-karyote (“good” + “cell”) was fitter than either by itself, so the lineage of eukaryotes prospered.*

**What potential synergies are there in the world of goods and services that is currently not discovered? How does one discover those things? Bruteforce trial and error? How does one speed up that process? Is evolution slow or is it in fact really fast? Somehow it seems exponential, meaning it's accelerating. How does one build an accelerating business? How fast can one feasibly iterate on widely ranging ideas? Nature is brutal and it can't lie. 

---
Page: 270

*Sex reveals that a crane of great power may exist that was not created in order to exploit that power; it was created for other reasons, although its power as a crane may help explain why it has been maintained ever since. A crane that was obviously created to be a crane is genetic engineering. Genetic engineers can now unquestionably take huge leaps through Design Space, creating organisms that would never have evolved by “ordinary” means. This is no miracle provided that genetic engineers (and the artifacts they use in their trade) are themselves wholly the products of earlier, slower evolutionary processes.*

**The products of evolution is simply what survives. It becomes a bit of a tautology in that way, that's why you need to reason about design in nature. You can then explain after the fact why a thing survived. Nature tries all possibilities at the same time and sifts it every step of the way. What are the hurdles something needs to jump through to get to the other side? Live long enough to reproduce, that's pretty much the criterion. Or long enough to have protected something similar to yourself. Live long enough to let the idea or image of you carry on. 

---
Page: 276

*There are reasons aplenty for these behaviors, but in general, organisms need not understand them. They are endowed with behaviors that are well designed by evolution, and they are the beneficiaries of these designs without needing to know about it. This feature is everywhere to be seen in nature, but it tends to be masked by our tendency, adopting the intentional stance, to interpret behavior as more mindful and rational than it really is. How clever the termites are to air-condition their castles with well-placed ventilation shafts! How sagacious the squirrel is to store away food for the winter! How wily the pickerel is to hover motionless as its prey approaches! These are indeed excellent strategies for success in the unrelentingly competitive world of nature, but their beneficiaries need not appreciate what we do when we figure them out. We are the first minds to represent the reasons that account for the success of these arrangements.*

**What reasons are beyond our own comprehension? What role does culture play in this? 

**Since we're able to represent reasons, is there any reason we cannot understand?

---
Page: 276

*There are reasons why trees spread their branches, but they are not in any strong sense the trees’ reasons. Sponges do things for reasons; bacteria do things for reasons; even viruses do things for reasons. But they don’t have the reasons; they don’t need to have the reasons.*

**What makes those creatures "try" new things? Is it just by accident? Mutations? Are they forced to by changes in their environment? What's the role of equilibrium? 

---
Page: 278

*It should be clear that the soundness of this explanation (which may not yet be established) does not depend on any hypothesis suggesting that locusts understand arithmetic, let alone prime numbers. Nor does it depend on the process of natural selection understandingprime numbers. The mindless, uncomprehending process of natural selection can exploit this important property of some numbers without having to understand it at all. For another example: neither bees nor Mother Nature need to understand the geometry that declares the hexagon the ideal shape for cells in a honeycomb. Many more examples of evolution’s mathematical competence-without-comprehension could be cited.*

**I like the term "free-floating rationale" more and more. 

---
Page: 281

*This is the free-floating rationale, and it need not be appreciated by either gazelle or predator. That is, the gazelle may be entirely oblivious to why it is a good idea to stot if it can, and the predator, say, a lion, may not understand why it finds stotting gazelles relatively unattractive prey, but if the signaling wasn’t honest, costly signaling, it couldn’t persist in the evolutionary arms race between predator and prey. (If evolution tried using a “cheap” signal, like tail-flicking, which every gazelle, no matter how strong or weak, could send, it wouldn’t be worth it for lions to pay attention to it, so they wouldn’t.) These explanations in terms of free-floating rationales are not reducible to explanations at lower levels, such as the molecular level, but it is important to recognize that even though the explanation of why and how stotting works is from the intentionalstance (in terms of what it would be rational for a lion to conclude from the stotting of the gazelle), the individual lion or gazelle need not understand the meaning of stotting for it to work; they need only sorta understand it.*

**What does the calibration process look like for these kinds of signals? How did the stotting get going? Perhaps it was just something that got exapted? Some particularly energetic gazelles just happened to do it, and the lions who weren't able to discern these strong gazelles that went after them failed in bioeconomics and weren't able to gather more energy than they spent. 

---
Page: 284

*Suppose we list ten major differences used to distinguish therapsids from mammals, and declare that having five or more of the mammal marks makes an animal a mammal. Aside from being arbitrary—why ten differences instead of six or twenty, and shouldn’t they be ordered in importance?—any such dividing line will generate lots of unwanted verdicts, since during the long, long period of transition between obvious therapsids and obvious mammals there will be plenty of instances in which mammals (by our five-plus rule) mated with therapsids (less than five mammal marks) and had offspring that were therapsids born of mammals, mammals born of therapsids born of mammals, and so forth! Of course we would need a time machine to see all these anomalies, since the details are undetectable after all those millions of years. It’s just as well, since the details don’t really matter in the long run. What should we do? We should quell our desire to draw lines. We don’t need to draw lines. We can live with the quite unshocking and unmysterious fact that all these gradual changes accumulated over many millions of years and eventually produced undeniable mammals. Similarly the differences between lakes, ponds, and wetlands or marshes do not need to be calibrated, even by limnologists (those who study inland waters).*

**It's a morphing kind of process. It does seem like we're switching between two equilibrium, so the distinction makes more sense looking over a period of time rather than any one instance in time. If you look over a long arc of history it's easy for everyone to see. 

---
Page: 286

*But what if there are apparently lots of intermediate cases about which it isn’t clear whether they are A or not-A (mammals or not mammals, alive or not alive, conscious or not conscious, a belief or not a belief, moral or not moral, etc.)? In order to brush aside this worry, you must “draw a line” distinguishing the A from the not-A and banishing all sorta talk. Without that sharp boundary, marking the essence of whatever is at stake, the argument simply can’t be constructed. Such arguments work brilliantly in mathematics, where you really can draw the lines. Every integer really is odd or even, and every number really is rational or not rational, and every polygon really is a (three-sided) triangle or not. Outside of such abstract domains, these arguments fare less well.*

**Can we be structured with the unstructured and the fuzzy? Many of the most important things cannot be neatly organized but we should be able to draw conclusions and make predictions about them nonetheless. 

---
Page: 289

*Populations of conspecifics often get divided by environmental events into two (or more) isolated groups, which stay reproductively isolated from each other for a few generations, and almost always either these groups reunite again or one group goes extinct. So although such first steps to speciation must happen fairly often, they almost never lead to speciation, and when they do, it is an outcome that takes many hundreds of generations to establish. Absolutely nothing about the circumstances of the initial separation could tell you whether they were the beginnings of a speciation event, even if you had perfect physical knowledge of every molecule in the world at the time. The very concept of a species is a sorta concept.*

**What is it that changes so they no longer are reproductively compatible? 

---
Page: 294

*To bring out just how un-special Mitochondrial Eve—that is, Amy—probably was, suppose that tomorrow, thousands of generations later, a virulent new disease were to spread around the earth, wiping out 99 percent of the human race in a few years. The survivors, fortunate to have some innate resistance to the disease virus, would probably be quite closely related. Their closest common direct female ancestor—call her Betty—would be some woman who lived hundreds or thousands of generations later than Amy, and the crown of Mitochondrial Eve would pass to her, retroactively. She may have been the source of the mutation that centuries later became a species-saver, but it probably didn’t do her any good, since the virus against which it triumphs probably didn’t exist in its virulent form then. The point is that Mitochondrial Eve can only be retrospectively crowned. This historically pivotal role is determined not just by the accidents of Amy’s own time, but by the accidents of later times as well. Talk about massive contingency!*

**Some features of you or ideas associated with you may only become meaningful long after you're dead. Don't be sad if you don't get any recognition, you're not out of the race as long as some parts of you are preserved. 

---
Page: 300

*Computer programmers have been exploring the space of possible computations for less than a century, but their harvest of invention and discovery so far includes millions of loops within loops within loops. It turns out that all the “magic” of cognition depends, just as life itself does, on cycles within cycles of recurrent, “re-entrant,” reflexive information-transformation processes ranging from the nano-scale biochemical cycles within each neuron, through the generate-and-test cycles of predictive coding in the perceptual systems (see Clark, 2013, for a brilliant survey), to the whole brain sleep cycle, large-scale waves of cerebral activity and recovery that are revealed by EEG recordings. The secret ingredient of improvement everywhere in life is always the same: practice, practice, practice.*

**What cycles at what levels would be useful for ai? The technological evolution cycle is not fast enough to make something adaptive. The training cycle is interesting, it should keep learning forever, the training shouldn't be a discrete event. 

---
Page: 300

*How did all those seasonal cycles, water cycles, geological cycles, and chemical cycles, spinning for millions of years, gradually accumulate the preconditions for inaugurating the biological cycles? Probably the first thousand “tries” were futile, near misses. But as the wonderfully sensual song by George Gershwin and Buddy DeSylva reminds us, see what happens if you “do it again” (and again, and again).*
A good rule of thumb, then, when confronting the apparent magic of the world of life and mind is to look for the cycles that are doing all the hard work.*

**The cycles of product development and innovation are pretty fascinating. It couldn't be anything other than iterative and incremental. Same should be true for intelligence. You learn, apply and adjust. 

---
Page: 304

*The idea that there must be something determinate that the frog’s eye really means—some possibly unknowable proposition in froggish that expresses exactly what the frog’s eye is telling the frog’s brain—is just essentialism applied to meaning (or function). Meaning, like function, on which it so directly depends, is not something determinate at its birth. It arises not by saltation—huge leaps in Design Space—or special creation, but by a (typically gradual) shift of circumstances.*

**Can you create conditions that catalyzes exaptation? Take a function and put it in a different environment and see what happens. This should be done over and over again while exploring ideas. What should one have in mind while doing this?

---
Page: 307

*The R & D that went into creating that sequence is too specific to be duplicated by chance. Why? What is the particularity that marks such a string of symbols? Nicholas Humphrey (1987) makes the question vivid by posing a more drastic version: if you were forced to “consign to oblivion” one of the following masterpieces, which would you choose: Newton’s Principia, Chaucer’s CanterburyTales, Mozart’s Don Giovanni, or Eiffel’s tower? “If the choice were forced,” Humphrey answers,
I have little doubt which it should be: the Principia would have to go. How so? Because, of all those works, Newton’s was the only one that was not irreplaceable. Quite simply: if Newton had not written it, then someone else would—probably within the space of a few years. … The Principia was a glorious monument to human intellect, the Eiffel Tower was a relatively minor feat of romantic engineering; yet the fact is that while Eiffel did it his way, Newton merely did it God’s way.*

**The same is true for technology in a sense. There will be some technology that is inevitable. Then there will be some technology that is born like art. 

---
Page: 312

*You may be tempted to insist at this point that when Deep Blue beats Kasparov at chess, its brute-force search methods are entirely unlike the exploratory processes that Kasparov uses when he conjures up his chess moves. But that is simply not so—or at least it is not so in the only way that could make a difference to the context of this discussion of the Darwinian perspective on creativity. Kasparov’s brain is made of organic materials and has an architecture importantly unlike that of Deep Blue, but it is still, so far as we know, a massively parallel search engine that has built up, over time, an outstanding array of heuristic pruning techniques that keep it from wasting time on unlikely branches. There is no doubt that the investment in R & D has a different profile in the two cases; Kasparov has methods of extracting good design principles from past games, so that he can recognize, and know enough to ignore, huge portions of the game space that Deep Blue must still patiently canvass seriatim. Kasparov’s “insight” dramatically changes the shape of the search he engages in, but it does not constitute “an entirely different” means of creation. Whenever Deep Blue’s exhaustive searches close off a type of avenue that it has some algorithmic way of identifying as probably negligible (a difficult, but not impossible task), it can reuse that R & D whenever it is appropriate, just as Kasparov does. Deep Blue’s designers have done much of this analytical work and given it as an innate endowment to Deep Blue, but Kasparov has likewise benefitted from the fruits of hundreds of thousands of person-years of chess exploration transmitted to him by players, coaches, and books and subsequently installed in the habits of his brain.*

**Creativity in the end is just a search in design space. We may have different ways of pruning and setting starting points, but it's a mechanical process at the bottom. Creativity is in a way solved. How do we decide on goal posts when it doesn't come to games?

---
Page: 317

*In his book Le Ton Beau de Marot, Doug Hofstadter (1997) draws attention to the role of what he calls spontaneousintrusions into a creative process. In the real world, almost everything that happens leaves a wake, makes shadows, has an aroma, makes noise, and this provides a bounty of opportunities for spontaneous intrusions. It is also precisely what is in short supply in a virtual world. Indeed one of the chief beauties of virtual worlds, from the point of view of computer modelers, is that quietness: nothing happens except what you provide for, one way or another. This permits you to start with a clean slate and add features to your model one at a time, seeing what the minimal model is that will produce the sought-for effects.
This absence of noise makes computer simulations of evolution extremely limited, since evolution by natural selection feeds on noise, turning fortuitously encountered noise into signal, junk into tools, bugs into features.*

**How do you create environments for algorithms that contain useful noise? How do you introduce nature like variability in ai training? How do you create a learning environment that algorithms can interact with, without falling through the proverbial floors? How do you create the opportunity for serendipity? 

---
Page: 319

*But consider how counterintuitive such advice would appear:
No matter what you’re modeling, make sure that every phenomenon, every subroutine, everything that happens in that world broadcasts a variety of nonfunctional effects through the world: makes extraneous noises, leaves a wake, sheds dust, causes vibrations, and so forth.
Why? What is all this noise for? It’s not for anything; it’s just there so that every other process has that noise as a potential source of signal, as something that it might turn, by the alchemy of the creative algorithm, into function, into art, into meaning. Every increment of design in the universe begins with a moment of serendipity, the undesigned intersection of two trajectories yielding something that turns out, retrospectively, to be more than a mere collision. But to the extent that computer modelers follow this advice, they squander the efficiency that makes computers such great tools. So there is a sort of homeostasis here. We can see that, not for any mysterious reason, computer modeling of creativity confronts diminishing returns. In order to get closer and closer to the creativity of a human composer, the model has to become ever-more concrete; it has to model more and more of the incidental collisions that impinge on an embodied composer.*

**What would it mean to create a virtual world that's richer than the real world in spontaneous intrusions? Is there a balance to be struck? 

**Serendipity is almost like a teleporter in design space. Two seemingly unmergable ideas open up a portal to a new and interesting place in design space. 

---
Page: 323

*Is the resulting infant, Hal, the child of Herb and Alice? It seems to me to be quite obvious that Hal is indeed their biological offspring, since it avails itself of all the genetic information they would contribute if Hal were conceived in the normal way. This intuition pump highlights the importance of what matters in reproduction: information, and the causal transmission of information (in this case, in the form of ASCII code for “A,” “C,” “G,” and “T,” not in the form of molecules). The causal link might, for instance, pass through telecommunication satellites, instead of taking the more direct, biochemical routes. [Drawn with revisions from personal correspondence, April 26, 2010]*

**I wonder if the meiosis algorithm could ever match the one that happens in reality, and not be victim of a too noisefree environment. Perhaps the noise itself is easily reproducible? Perhaps it's environment is isolated enough that you don't have to simulate the universe just to simulate the noise?

---
Page: 327

*nongenetic, cultural selection, accomplished by the same process of mindless natural selection that gives us the genes. A vivid example is provided by an observation about Polynesian canoes more than a century old: “every boat is copied from another boat. … it is the sea herself who fashions the boats, choosing those which function and destroying the others” (Alain, 1908). This is natural selection, plain as day: the islanders have a simple rule: if it returns from the sea intact, copy it! They may have considerable comprehension of the principles of naval architecture that retrospectively endorse their favorite designs, but it is strictly unnecessary. Evolution takes care of the quality control. The same is true of grammatical rules, words, religious practices, and many other bedrock features of human culture: nobody designed them, and they’re not “in our genes,” but they are nevertheless quite excellently designed.*

**What do you throw your creations at to do the quality control? Having bountiful access to something that can refine your design is extremely valuable. AB tests are quite close to creating an efficient way of evolution although I think they tend to locally optimize. 

---
Page: 348

*Never forget William Bateson’s failure of imagination. When I try my hardest to avoid that trap, hunting for loopholes in my background assumptions, keeping my eye peeled for ways in which I could be proved wrong about zombies, I always come up with imagined discoveries that show, at most, that the whole concept of consciousness is seriously confused. For instance, I can imagine that there might be two (or seven, or ninety-nine) different sorts of so-called consciousness, and lefties have one, and righties have another, and lobsters have yet another. But the only way I can imagine this (so far) is by imagining that they are distinguishable by the following functional differences: lefties can’t do X, and righties can’t do Y, and so on. But those distinguishable differences just go to show that we’re not talking about philosophical zombies after all, for (by definition) there are no distinguishable-from-the-outside differences between philosophical zombies and “genuinely conscious” people.*

**It does feel like zombies do more harm than good. They essentially try to isolate consciousness from its functions, turning it into a kind of wonder tissue. 

---
Page: 354

*The functional states that signaled or represented colored things in front of the robot’s television camera eyes would not have that extra something that we have. Thomas Nagel’s famous essay “What Is It Like to Be a Bat?” (1974) provides us with a standard way of alluding to the conscious states, if any, of an entity. It wouldn’t be like anything to be a robot having an afterimage. Why do so many people think this is obvious? It might be because they are imagining a relatively simple robot and failing to note that you can’t draw conclusions about all robots from facts about all simple robots. Of course if you define qualia as intrinsic properties of experiences considered in isolation from all their causes and effects, and logically independent of all dispositional properties, then qualia are logically guaranteed to elude all functional analysis. No amount of clever engineering could endow a robot with qualia—but this is an empty victory, since there is no reason to believe such intrinsic properties exist.*

**Until we find a true way of determining whether other human beings have consciousness or not, we certainly won't be able to judge whether a robot has consciousness or not. This is an area where it's so easy to get into making assumptions. 

---
Page: 356

*There are many properties of conscious states that can and should be subjected to further scientific investigation right now, and once we get accounts of them in place, we may well find that they satisfy us as an explanation of what consciousness is. After all, this is what happened in the case of the erstwhile “mystery” of what life is. Vitalism—the insistence that there is some big, mysterious extra ingredient in all living things, dubbed élan vital—turns out to have been a failure of imagination. Vitalism today is all but extinct, though there are still a few cranks around who haven’t given up. Inspired by that happy success story, we can proceed with our scientific exploration of consciousness. If the day arrives when all the demonstrable features of consciousness are explained, all the acknowledged intellectual debts are paid, and we plainly see that something big is missing (it should stick out like a sore thumb at some point, if it is really important), those with the unshakable hunch will get to say they told us so*

**Ongoing phenomena that are close enough to us will always be explainable after long enough time. Is this true or is there anything within our vicinity that we could never ever explain?

---
Page: 360

*In Capgras, the conscious, cortical face-recognition system is spared—that’s how the deluded sufferer recognizes the person standing in front of him as the spitting image of his loved one—but the unconscious, limbic system is disabled, draining the recognition of all the emotional resonance it ought to have. The absence of that subtle contribution to identification is so upsetting (“Something’s missing!”) that it amounts to a pocket veto on the positive vote of the surviving system’s identification of the familiar person: the emergent result is the sufferer’s heartfelt conviction that he or she is looking at an impostor. Instead of blaming the mismatch on their own faulty perceptual system, Capgras sufferers blame the world, in a way that is so metaphysically extravagant, so improbable, that there can be little doubt of the power (the political power, in effect) that the impaired unconscious face-recognition system normally has in us all. When this particular system’s epistemic hunger goes unsatisfied, it throws such a fit that it overthrows the contributions of the other systems.*

**Would it serve us to be better able to translate the emotions that our limbic system sends us? Then we'd be able to better know whether to agree with it or not. The annoying thing is that a feeling of wrongness can rarely be wrestled out of the system, although certain kinds of mindfulness helps. 

---
Page: 363

*What I want to know is simply how philosophers mean to use the word “qualia”—do they identify all changes in subjective response as changes in qualia, or is there some privileged subset of responses that in effect anchor the qualia? Is the idea of changing one’s aesthetic opinion about—or response to—a particular quale nonsense or not? Until one makes decisions about such questions of definition, the term is not just vague or fuzzy; it is hopelessly ambiguous, equivocating between two (or more) fundamentally different ideas.
Have Clapgras’s color qualia been inverted? Some philosophers say that I haven’t given enough detail in describing his condition. I have described his behavioral competences—he recognizes, and discriminates, and names colors correctly, while responding “wrong” in many other regards—while avoiding describing his subjective state.*

**We need a better experimental grip on this subject. Getting clearer on the definitions can help us I suppose, but they should get continuously revised based on the experiments. 

**The qualia in this example, unfortunately, seems to be a fuzzy combination between the conscious response and unconscious response, since apparently the mismatch made the subject uncomfortable. 

---
Page: 372

*Hull’s trick was introducing a single common word: “the”—for heaven’s sake! This modest monosyllable seduced his audience of experts, paralyzing their minds, preventing them from jootsing. They found themselves stuck in a system in which they were sure that they had to find a big, new trick, so they couldn’t see that their problem(s) had not one solution but many; they failed to jump out of the system.
I am suggesting, then, that David Chalmers has—unintentionally—perpetrated the same feat of conceptual sleight of hand in declaring to the world that he has discovered “The Hard Problem.” Is there really a Hard Problem? Or is what appears to be the Hard Problem simply the large bag of tricks that constitute what Chalmers calls the Easy Problems of Consciousness? These all have mundane explanations, requiring no revolutions in physics, no emergent novelties. They succumb, with much effort, to the standard methods of cognitive science.*

**Of course you're able to break down any problem into subproblems, but what's interesting with the tuned deck is that each trick that it uses is discrete, only connected by their umbrella trick, and that's why it's hard to get a grip on it. 

---
Page: 374

*We know, for instance, that negative (alarming, fear-inducing) reactions can be triggered quite early in the perceptual process, and they then “color” all subsequent processing of that perceptual input, in which case we could say that the emotional reactions cause the qualia to have the subjective character they had for Clapgras, rather than (vice versa) that the “intrinsic” nature of the qualia cause or ground the emotional reactions. But if we’ve already arrived at the emotional (or aesthetic or affective) reactions to the perceptual input, we have no more “work” for the qualia to do, and, of course, a zimbo would be just as bummed out by inverted reactions-to-perceptions as a conscious person is.*

**Emotions come first, through physical processes, then we put attention on them and perceive them. 

---
Page: 372

*The inventory of known effects of consciousness is large and growing, and they range from the mundane to the exotic. It’s hard to keep track of them all, so we must be alert to the possibility that we are being victimized by an error of arithmetic, in effect, when we take ourselves to have added up all the Easy Problems and discovered a residue unaccounted for. That residue may already have been accommodated, without our realizing it, in the set of mundane phenomena for which we already have explanations—or at least un-mysterious paths of explanation still to be explored. How could we commit this “error in arithmetic” and then overlook it? By double counting the phenomena or by forgetting that we had already explained some phenomenon, and hence should have erased it from our list of “Still-to-Be-Explained Phenomena.”*

**The tractable problems seems wisest to focus on first and once those are accounted for, looking for any remainders seems like the best way to smoke any kind of thing that cannot be gripped by science. 

---
Page: 377

*We found his thought experiment fascinating because it was, on the one hand, so clearly a fallacious and misleading argument, yet, on the other hand, just as clearly a tremendous crowd-pleaser and persuader. How—and why—did it work? We looked at it from the point of view of reverse engineering, and Doug came up with the tactic of “turning all the knobs” to see what makes it work. Is the story robust under deformation, or does it critically depend on details that ought to be optional?*

**Reverse engineering the inner workings of ideas is great for creating true understanding. 

---
Page: 378

*I found myself thinking, “Hit them again, Murray! Sock it to them!” Here was a world-famous Nobel laureate physicist supporting my prejudice, using arguments that I understood. This was my kind of quantum physics! But then it hit me. Did I really understand his arguments, or just sorta understand them? Could I be sure that I wasn’t just falling for his rhetoric? I hoped there weren’t other physicists who would want to drag me back through the technicalities, showing me that I had been taken in by this authoritative dismissal. I liked his conclusion so much I didn’t have any stomach for the details. Same copout.*

**We get kind of primal when our biases are tickled. Be mindful of that feeling and use it as a signal for being extra attentive. 

---
Page: 384

*Look at what we’ve just done. We’ve turned the knob on Searle’s intuition pump that controls the level of description of the program being followed. There are always many levels. At the highest level, the comprehending powers of the system are not unimaginable; we even get insight into just how the system comes to understand what it does. The system’s reply no longer looks embarrassing; it looks obviously correct. That doesn’t mean that AI of the sort Searle was criticizing actually achieves a level of competence worth calling understanding, nor that those methods, extended in the ways then imagined by those AI researchers, would likely have led to such high competences, but just that Searle’s thought experiment doesn’t succeed in what it claims to accomplish: demonstrating the flat-out impossibility of Strong AI.*

**Searle's experiment seems equivalent to me to imagining the cpu being conscious. If you start from there it's obvious that comprehension cannot be in the cpu alone, it's in the whole system, including the code and the originator of the code. A computer that plays chess has no comprehension but it has competence. 

---
Page: 381

*The way to reproduce human competence and hence comprehension (eventually) is to stack virtual machines on top of virtual machines on top of virtual machines—the power is in the system, not in the underlying hardware. Darwin’s “strange inversion of reasoning” is nicely echoed by Turing’s strange inversion of reasoning (Dennett, forthcoming): whereas we used to think (before Turing) that human competence had to flow from comprehension (that mysterious fount of intelligence), we now appreciate that comprehension itself is an effect created (bubbling up) from a host of competences piled on competences.*

**There can be competence without comprehension and comprehension itself is a kind of competence, though a complex one built up from lots of simpler ones. 

---
Page: 388

*A song or a poem or a movie can undoubtedly be teleported. Is a self the sort of thing—a thing “made of information”—that can be teleported without loss? Is our reluctance to admit the teleportation of people a bit like the anachronistic resistance, recently overcome in most quarters, to electronically scanned legal signatures on documents?*

**The more we learn about the universe the more materialist we become, since we understand and make use of the inner workings of different phenomena. There's no real reason, other than fear or hope, to think the trend won't continue. 

---
Page: 393

*It may be a “theorist’s fiction,” but it is a very valuable fiction from which a lot of true predictions can be generated. Can such an abstract entity, having no material existence, actually cause anything? Not directly, but explanations that cite a center of gravity compete with explanations that are clearly causal. Why didn’t that coffee mug tip over when the sailboat heeled so drastically? “Because it has an unusually low center of gravity” competes with “Because it is glued to the deck.”*

**The self is like a nexus of lots of small phenomena. Lots of competences that you have. When you plan and so on, it has a huge impact on our cognition overall.

---
Page: 403

*Then there are a host of physiological dependent variables to measure, from galvanic skin response and heart rate to changes in facial expression and posture. And if you, the subject, believe that there are still ineffable residues unconveyed after exhausting such methods, you can tell this to the heterophenomenologists, who can add that belief to the list of beliefs in your primary data:
S claims that he has ineffable beliefs about X.
If this belief is true, then science has the obligation to explain what such beliefs are and why they are ineffable. If this belief is false, science still has to explain why S believes (falsely) that there are these particular ineffable beliefs.**

**Explaining why something is ineffable still leaves out the actual experience of it. I do feel that with enough imagination we'll be able to catalogue every conscious experience rather accurately, but I believe that the shorthand of first-person knowledge of the fact will give you yourself a better understanding and thus you'll be able to explain it better. I wouldn't trust someone whose only read about riding a bike to be able to ride it for real. Would I trust that person as being able to write down an account of someone who has experienced it firsthand? Probably not. I assume that much of our processing is unconscious, but nevertheless those are the processes whose tips stick out of the water. There's many things in the unknown unknown set that won't easily be uncovered through interrogation. 

---
Page: 408

*Jackson’s intuition pump excellently exposes to the light a lot of naïve thinking about the nature of color experience and the brain that no doubt serves people well most of the time, so we might grant that he nicely draws out some of the implications of folk theory. But his aim was to refute a hypothesis about the capacity of the physical sciences to account for all color phenomena. Of course in any real-world situation, somebody in Mary’s imagined position would learn something new because however much she knew about color, there would be lots of facts about physical effects of color she didn’t know. It is only the stipulated extreme case that makes Jackson’s “just obvious” and Graham and Horgan’s “surely” out of place.*

**I do see what he means about the infeasible fact of propositionally knowing every physical fact about something. Though it doesn't necessarily discredit the conclusion fully. Can we imagine a more pragmatic scenario? Imagine a person who's able to study the riding of a bike with every means possible except for riding a bike. That person would most likely stumble a little bit on his first try. Although, how close are we allowed to get to actually riding a bike? Are we allowed to train with a kickbike? If you get close enough you may actually not stumble. Having said that, you'd learn something new if you've only had one bike your entire life and then try a new one. It'd have different resistance, weight, handling, etc. 

**The process by which knowledge is acquired matters to what kind of knowledge you get. There are muscles, nerves and motorcortex interactions that won't happen unless they're physically exercised. 

**In theory a physicalist materialist approach to acquiring knowledge without first-person experience may be true, but it's infeasible for any one person to acquire and use that knowledge. 

---
Page: 415

*Unfortunately, some of the scientists who now declare that science has shown that free will is an illusion go on to say that this “discovery” matters, in a morally important sense. They think it has major implications for morality and the law: nobody is ever really responsible, for instance, so nobody ever deserves to be either punished or praised. They are making the mistake people make when they say that nothing is ever solid, not really. They are using an unreconstructed popular concept of free will, when they should be adjusting it first, the way they do with color and consciousness (and space and time and solidity and all the other things that the ideology of the manifest image gets wrong).*

**Folkpsychology is in a way easy to manipulate, at least when it is able to confirm how things feel to us. Some scientists confirm the magic for us, and entrenches our biases. Some scientists completely discard the manifest image of people and thus leave out things that are shared stories but nonetheless real and worthy of scientific inquiry. 

---
Page: 417

*It really doesn’t matter whether the court believed his testimony or hers, whether it sentenced him or her; either way she ruined his life with her ill-considered assertion, robbing him of his integrity and crippling his power to make decisions. In fact, her false “debriefing” of her patient actually accomplished nonsurgically much of what she claimed to accomplish surgically: she disabled him.*

**Our software is very malleable, we can manipulated to feel that something is true and start acting accordingly. 

**A simpler example would be, imagine someone showed you a video of your friend committing horrible deeds, you would forever act differently towards that person, but as it turns out what you saw was just a deep fake. A lie got you to change your beliefs and your behavior. 

---
Page: 424

*By the scrupulous application of our single law, one can predict with perfect accuracy the next instant of any configuration of ON and OFF cells, and the instant after that, and so forth. In other words, the Life world is a toy world that perfectly instantiates the determinism made famous by the early-nineteenth-century French scientist Pierre Laplace: given the state description of this world at an instant, we observers can perfectly predict the future instants by the simple application of our one law of physics. Or we could put it this way: when we adopt the physical stance toward a configuration in the Life world, our powers of prediction are perfect: there is no noise, no uncertainty, no probability less than one. Moreover, it follows from the two-dimensionality of the Life world that nothing is hidden from view. There is no backstage; there are no hidden variables; the unfolding of the physics of objects in the Life world is directly and completely visible.*

**Is it meaningful to think about the designer of this law and the medium in which it's instantiated? That may go beyond the purpose of the demonstration. 

---
Page: 428

*Conway and his students also set out to confirm this with their own exercise in two-dimensional engineering.†
It was far from easy, but they showed how they could “build” a working computer out of simpler Life forms. Glider streams can provide the input-output “tape,” for instance, and the tape-reader can be some huge assembly of eaters, gliders, and other bits and pieces. What does this machine look like? Poundstone (1985) calculated that the whole construction would be on the order of 1013 cells or pixels.
Displaying a 1013-pixel pattern would require a video screen about 3 million pixels across at least. … [Imagine a screen with the high resolution of your laptop or iPad, a half a mile wide.] Perspective would shrink the pixels of a self-reproducing pattern to invisibility. If you got far enough away from the screen so that the entire pattern was comfortably in view, the pixels (and even the gliders, eaters and guns) would be too tiny to make out. A self-reproducing pattern would be a hazy glow, like a galaxy.*

**What prevents us from doing it in higher dimensions? The dimensions could be simulated right? How small could a computer be in four dimensions? Can four dimensions be simulated? 

**It's quite incredible that from simple rules complexity emerges, and from that complexity life can be designed, and since it can be designed, eventually it'd be found on its own. 

---
Page: 427

*Notice too that whereas at the physical level, there are absolutely no exceptions to the general law, at this level our generalizations have to be hedged: they require “usually” or “provided nothing encroaches” clauses. Stray bits of debris from earlier events can “break” or “kill” one of the objects in the ontology at this level. Their salience as real things is considerable, but not guaranteed. To say that their salience is considerable is to say that one can, with some small risk, ascend to this design level, adopt its ontology, and proceed to predict—sketchily and riskily—the behavior of larger configurations or systems of configurations, without bothering to compute the physical level. For instance, one can set oneself the task of designing some interesting super-system out of the “parts” that the design level makes available.*

**In the game of life, it's quite clear to me that it demonstrates the true principles of life. What about it makes it dynamic? What happens if the rules are tweaked? Does the universe become sterile then or even more dynamic? How does stable groupings of units come about? 

---
Page: 443

*Now whether or not the whole universe is deterministic, computers are designed to be deterministic in the face of submicroscopic noise and even quantum randomness, absorbing these fluctuations by being digital, not analog. (We saw a vivid example of that with Conway’s game of Life in chapter 66, but digital determinism is everywhere.) The fundamental idea behind digitizing in order to produce determinism is that we can create inert historical facts by design. Forcibly sorting all the pivotal events into two categories—high vs. low; ON vs. OFF; 0 vs. 1—guarantees that the micro-differences (between different high voltages, different flavors of being ON, different shades of 0) are ruthlessly discarded. Nothing is allowed to hinge on them, and they vanish without a trace, facts about actual historical variations that make no difference at all to the subsequent series of states through which the computer passes.*

**Does the digitization of computers make them too coarse? Is ineffability a necessary component for life?

---
Page: 439

*The two lotteries give us a new perspective on the problem of determinism. If the world is determined, then we have pseudo-random number generators in us, not truly (quantum-mechanical) random randomizers. If our world is determined, all our lottery tickets were drawn at once, in effect, about fourteen billion years ago at the moment of the Big Bang, put in an envelope for us, and doled out as we needed them through life. Whenever you need to “flip a coin” or in some less ostentatious way make a chancy decision, your brain opens the envelope and takes out the next “random” number, letting its value determine what you do, just like the list of moves in “rock, paper, and scissors.”*

**The two lotteries are the same but other one somehow makes us feel better. We're able see for ourselves a demonstration of the randomness that went into it. Practically it should make no difference. 

---
Page: 453

*So here we have an entirely deterministic world—program T—in which A could have castled but B could not have castled. The difference between A and B is real and explanatory, a difference in competence or ability. One way we could put it is apparently paradoxical:
A could have castled at time t but the universe couldn’t have had a castling event at time t.
What could possibly license this way of describing the situation? Simply this: if we consider A divorced from its immediate environment—which includes the random-number generator— then whether A castles or not is undetermined. It depends on something that is strictly speaking outside A. Given the way the rest of the universe was arranged at t, castling was not possible for A, but that is “not A’s fault.” B, in contrast, could not have castled; it was not in B’s nature to castle. To imagine B castling would require too many alterations of reality.
This is a useful discovery: a distinction between what A and B “could do” that does not depend on indeterminism. Even in a deterministic world we can see that A can do kinds of things that B cannot do, and this difference is part of the explanation of why A beats B. The fact that, because determinism is true in this world, A and B can only do what they actually do on the specific occasion (and would do it again and again if exactly the same circumstances were repeated) is simply not interesting, not relevant to the explanation we get of the perfectly objective and visible regularity: A beats B.*

**What part does repetition play in this? If we run similar situations over and over then, as established, we'll see patterns forming that mark the difference in competence. 

**What does the starting point mean in all of this? Before A has been able to become more competent than B? And what role does developmental change play?

**I suppose it's not so much the "could've done differently" that's interesting but whether you can develop yourself such that you could've done differently. That's where we'd feel hurt if it's determined that you can't. However I think the capacity for change is the same for everyone, so practically it shouldn't be a concern. 

---
Page: 461

*I think it is just as obvious that people can gradually become morally responsible during their passage from infancy to adulthood as it is that lineages of reptiles and then therapsids can gradually become a lineage of mammals over the eons. You don’t have to be an absolute mammal to be a mammal, and you don’t have to be absolutely responsible to be responsible, or have absolute free will to have a kind of free will worth wanting. In fact, since absolute free will would be miraculous, there really needs to be a powerful argument to show why anybody would covet such a thing. Do they want to be God? Too bad, they’re out of luck, but the next best thing is quite a good thing to be.*

**You gradually gain more competency and agency as you grow older. It's only natural that the responsibility attached to your actions should grow proportionally. What should one think about people who are stuck developmentally? 

---
Page: 465

*Another thing you will notice about the puppeteer and neurosurgeon examples in the literature on free will is that the intervention is always—always—secret. Why should this be? Because it is only when we are unwittingly being caused to act or choose by some other, secret agent that the intuitions flood in to the effect that our will is not free. The reason for this is not far to seek, and harks back to the insight that inaugurated game theory: when an agent knows about the attempt at manipulation by another agent, it thereupon seeks countermeasures, and at the very least adjusts its behavior to better cope with this discovery. The competitive interactions between the two agents involve multiple levels of feedback, and hence diminishing “control” by the would-be manipulator. And if the intervention is not only not secret, but requested by the “puppet,” the tables are turned completely.*

**That's actually a fun knob to add. Imagine that your puppeteer must disclose every time he intervenes in one of your decisions. He cannot control your body. What would you do when he tells you he changed something? 

---
Page: 465

*Presumably the moral of these scary tales is that even if there is no actual puppeteer, the fact that our behavior is caused by various features of our environments, as processed through our perceptual systems and brains, shows that there might as well be a puppeteer. (The cover illustration of Sam Harris’s little book FreeWill (2012) is a set of puppeteer control strings.) But this invited conclusion is a clear non sequitur. When the “control” by the environment runs through our well-working perceptual systems and our undeluded brains, it is nothing to dread; in fact, nothing is more desirable than our being caused by the things and events around us to generate true beliefs about them that we can then use in modulating our behavior to our advantage. Photons bouncing off air holes in the tidal flats into my eyes are apt to cause me to grab my clam rake and basket and start digging. If this is a case of being controlled by my environment, I’m all for it. And, like most people, I do not feel threatened or manipulated when my friends offer me sumptuous meals, knowing full well that I will be unable to resist the temptation to eat them.*

**One part I wish he expanded on is the "use in modulating our behavior to our advantage". Are we in control of the modulation? 

---
Page: 471

*I am just claiming that this particular intuition pump is not at all to be trusted, since the (available, permissible) knob settings are interfering so much with our judgments. It may not have been designed to blow smoke, but it certainly manages to hinder clear thinking.*

**Intuition pumps shouldn't be rhetorical tools, they should help you gain true insight into a problem. 

---
Page: 478

*If Shakespeare hadn’t existed, nobody else would have written Hamlet or Romeo and Juliet or King Lear. If Van Gogh hadn’t existed, nobody else would have painted Starry Night. This may be a slight exaggeration, but there’s something to it. On the one hand, there is an individuality to the contributions of great artists that seems to be not just rare in science, but positively beside the point. The famous priority disputes in science, and the races for one Nobel Prize clincher or another, are ferocious precisely because somebody else could make exactly the contribution you were striving to make—and you won’t get points for style if you come in second. These contests have no parallel in the arts, where a different set of goals reigns.*

**Kind of makes me think that a product needs to have some art to it for it to be at a level where it couldn't have been created by anyone else. 

---
Page: 483

*One of the weaknesses of auto-anthropology is that one’s own intuitions are apt to be distorted by one’s theoretical predilections. Linguists have known for a long time that they get so wrapped up in their theories they are no longer reliable sources of linguistic intuition.*

**It's a bit unfortunate to lose yourself as a viable test subject, but gathering other perspectives is almost always the way.

---
Page: 491

*So what should you do? The tests I have mentioned—seeing if folks outside philosophy, or bright undergraduates, can be made to care—provide only warning signs; they are not definitive. Certainly there have been, and will be, forbiddingly abstruse and difficult topics of philosophical investigation well worth pursuing, in spite of the fact that the uninitiated remain unimpressed. I certainly don’t want to discourage explorations that defy the ambient presumptions about what is interesting and important. On the contrary, the best bold strokes in the field will almost always be met by stony incredulity or ridicule at first, and these should not deter you. My point is that you should not settle complacently into a seat on the bandwagon just because you have found some brilliant fellow travelers who find your work on the issue as unignorable as you find theirs. You may all be taking each other for a ride.*

**Don't dedicate your life to digging for truths about chmess. Think about if what you're doing will be worth anything in a few years. 

---
Page: 494

*In the end, you’re not taking any philosopher seriously until you ask whether or not what they say is right.*

**Do you believe what they're saying, why? Why not? Engage with the material don't just store it.

---
Page: 497

*Conceiving of something new is hard work, not just a matter of framing some idea in your mind, giving it a quick once-over and then endorsing it. What is inconceivable to us now may prove to be obviously conceivable when we’ve done some more work on it. And when we confidently declare that some things are truly impossible—a largest prime number, or a plane triangle with interior angles adding up to more than two right angles, or a married bachelor—it is not so much because we find these things inconceivable as that we find we have conceived of their components so well, so exhaustively, that the impossibility of their conjunction is itself clearly conceivable.
We haven’t yet succeeded in fully conceiving how meaning could exist in the material world, or how life arose and evolved, or how consciousness works, or whether free will can be one of our endowments, but we’ve made progress: the questions we’re posing and addressing now are better than the questions of yesteryear. We’re hot on the trail of the answers.*

**We shouldn't confuse where we are with where we will be in the future. 
